{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1c8898e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [2., 2., 2.],\n",
      "        [3., 3., 3.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "t_one =torch.Tensor([[1,1,1],[2,2,2],[3,3,3]]) \n",
    "print(t_one)\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "68b8c46c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('weight', Parameter containing:\n",
      "tensor([[-0.6081]], requires_grad=True))\n",
      "('bias', Parameter containing:\n",
      "tensor([0.6983], requires_grad=True))\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "model=nn.Linear(1,1)\n",
    "for i in model.named_parameters():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92d0ef5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('weight', Parameter containing:\n",
      "tensor([[0.0696]], requires_grad=True))\n",
      "('bias', Parameter containing:\n",
      "tensor([0.8162], requires_grad=True))\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "model = nn.Linear(1,1)\n",
    "\n",
    "for i in model.named_parameters():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa15e018",
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "import sklearn\n",
    "\n",
    "models = [sklearn.linear_model.LinearRegression]\n",
    "for m in models:\n",
    "    hyperparams = inspect.signature(m.__init__)\n",
    "    print(hyperparams)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c691339",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_two =torch.Tensor([[1,1,1],[2,2,2],[3,3,3]]) \n",
    "print(t_two)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e57fc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_prod=torch.mm(t_one,t_two)\n",
    "print(dot_prod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "2b7c8a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-2.)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "#forword pass\n",
    "w=torch.tensor(1.0,requires_grad=True)\n",
    "x=torch.tensor(1.0)\n",
    "y=torch.tensor(2.0)\n",
    "#forword pass ip op \n",
    "yy=w*x\n",
    "loss=(y-yy)**2\n",
    "#backward pass going back from op and apply grad for ip\n",
    "loss.backward()\n",
    "print(w.grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "5d73a48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.nn as nn\n",
    "\n",
    "# #model = nn.Linear(1,1)\n",
    "# for j in model.named_parameters():\n",
    "#     if j.requires_grad:\n",
    "#         #print(j)   \n",
    "#         print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5ec45e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/local/ZOHOCORP/abdul-pt6532/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "     Review_class\n",
      "0             0.0\n",
      "1             1.0\n",
      "2             1.0\n",
      "3             0.0\n",
      "4             1.0\n",
      "..            ...\n",
      "991           0.0\n",
      "992           0.0\n",
      "993           0.0\n",
      "994           0.0\n",
      "995           0.0\n",
      "\n",
      "[1996 rows x 1 columns]\n",
      "(1996, 1)\n",
      "torch.Size([1996, 1])\n",
      "tensor([[0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "data_hound = pd.read_csv(\"hound.txt\", delimiter='\\t', header=None)\n",
    "data_hound.columns = [\"Review_text\", \"Review_class\"]\n",
    "\n",
    "data_sample = pd.read_csv(\"sample.txt\", delimiter='\\t', header=None)\n",
    "data_sample.columns = [\"Review_text\", \"Review_class\"]\n",
    "\n",
    "# data_yelp = pd.read_csv(\"yelp_labelled.txt\", delimiter='\\t', header=None)\n",
    "# data_yelp.columns = [\"Review_text\", \"Review_class\"]\n",
    "\n",
    "data = pd.concat([data_hound,data_sample])\n",
    "data_hound.loc[1,[\"Review_text\"]]\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "nltk.download('stopwords')\n",
    "def clean_text(df):\n",
    "    all_reviews = list()\n",
    "    lines = df[\"Review_text\"].values.tolist()\n",
    "    for text in lines:\n",
    "        text = text.lower()\n",
    "        pattern = re.compile('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "        text = pattern.sub('', text)\n",
    "        text = re.sub(r\"[,.\\\"!@#$%^&*(){}?/;`~:<>+=-]\", \"\", text)\n",
    "        tokens = word_tokenize(text)\n",
    "        table = str.maketrans('', '', string.punctuation)\n",
    "        stripped = [w.translate(table) for w in tokens]\n",
    "        words = [word for word in stripped if word.isalpha()]\n",
    "        stop_words = set(stopwords.words(\"english\"))\n",
    "        stop_words.discard(\"not\")\n",
    "        PS = PorterStemmer()\n",
    "#         words = [w for w in words if not w in stop_words]\n",
    "        words = [PS.stem(w) for w in words if not w in stop_words]\n",
    "        words = ' '.join(words)\n",
    "        all_reviews.append(words)\n",
    "    return all_reviews\n",
    "\n",
    "all_reviews = clean_text(data)\n",
    "#all_reviews[0:20]\n",
    "stopwords.words(\"english\")\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "CV = CountVectorizer(min_df=3)   \n",
    "X = CV.fit_transform(all_reviews).toarray()\n",
    "y = data.loc[:,[\"Review_class\"]]\n",
    "print(type(X))\n",
    "print(type(y))\n",
    "y=y.dropna()\n",
    "print(y)\n",
    "print(y.shape)\n",
    "X=torch.tensor(X,dtype=torch.float32)\n",
    "y=y.to_numpy()#we cant chge directly from data frame  to tensor so 1st np array  then  torch\n",
    "y=torch.tensor(y,dtype=torch.float32)\n",
    "print(y.shape)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d8e621",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stochastic .graddescent in pytorch optimizers\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.nn import MSELoss, Parameter\n",
    "\n",
    "# The data function is: y = x + 10\n",
    "x_train = torch.tensor([1, 2, 3, 4])\n",
    "y_train = torch.tensor([11.0, 12.0, 13.0, 14.0])#, dtype=torch.float\n",
    "\n",
    "# Simple Linear Regression: a + bx\n",
    "a = torch.randn(1, requires_grad=True, dtype=torch.float)\n",
    "b = torch.randn(1, requires_grad=True, dtype=torch.float)\n",
    "\n",
    "# If we use nn.Module to create a model, it will model.parameters()\n",
    "model = [Parameter(a), Parameter(b)]\n",
    "\n",
    "criterion = MSELoss()\n",
    "# optimizer = torch.optim.SGD(model, lr=0.1)\n",
    "optimizer = torch.optim.Adam(model, lr=0.1)\n",
    "\n",
    "for epoch in range(10):#500\n",
    "    # Remove the grad computed in the last step\n",
    "    optimizer.zero_grad()\n",
    "    # Run a + bx\n",
    "    y_predicted = model[0] + model[1] * x_train\n",
    "    print(x_train, y_train, y_predicted)\n",
    "    loss = criterion(y_predicted, y_train)\n",
    "    loss.backward()\n",
    "    print(\"los is \",loss)\n",
    "    optimizer.step()\n",
    "    #print(model[0].grad)\n",
    "    #rint(model[1].grad)\n",
    " \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd940d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "model = nn.Linear(1,1)\n",
    "for i,j in model.named_parameters():\n",
    "        if j.requires_grad:\n",
    "            print(j )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef6696f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([0.8162], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.8162], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "#model = nn.Linear(1,1)\n",
    "for i,j in model.named_parameters():\n",
    "        print(j)   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27a839c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('weight', Parameter containing:\n",
      "tensor([[0.0696]], requires_grad=True))\n",
      "('bias', Parameter containing:\n",
      "tensor([0.8162], requires_grad=True))\n"
     ]
    }
   ],
   "source": [
    "for i in model.named_parameters():\n",
    "    print(i)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "07819701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([-0.0064], requires_grad=True), Parameter containing:\n",
      "tensor([-0.8454], requires_grad=True)]\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[-0.8518, -0.0064, -0.8518, -0.8518, -0.8518, -0.8518, -0.8518, -0.8518,\n",
      "         -0.8518, -0.8518, -0.8518, -0.0064]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(1.6746, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[-0.8318,  0.0036, -0.8318, -0.8318, -0.8318, -0.8318, -0.8318, -0.8318,\n",
      "         -0.8318, -0.8318, -0.8318,  0.0036]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(1.6299, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[-0.8118,  0.0136, -0.8118, -0.8118, -0.8118, -0.8118, -0.8118, -0.8118,\n",
      "         -0.8118, -0.8118, -0.8118,  0.0136]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(1.5859, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[-0.7918,  0.0236, -0.7918, -0.7918, -0.7918, -0.7918, -0.7918, -0.7918,\n",
      "         -0.7918, -0.7918, -0.7918,  0.0236]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(1.5426, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[-0.7719,  0.0336, -0.7719, -0.7719, -0.7719, -0.7719, -0.7719, -0.7719,\n",
      "         -0.7719, -0.7719, -0.7719,  0.0336]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(1.5001, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[-0.7519,  0.0436, -0.7519, -0.7519, -0.7519, -0.7519, -0.7519, -0.7519,\n",
      "         -0.7519, -0.7519, -0.7519,  0.0436]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(1.4583, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[-0.7321,  0.0535, -0.7321, -0.7321, -0.7321, -0.7321, -0.7321, -0.7321,\n",
      "         -0.7321, -0.7321, -0.7321,  0.0535]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(1.4173, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[-0.7122,  0.0634, -0.7122, -0.7122, -0.7122, -0.7122, -0.7122, -0.7122,\n",
      "         -0.7122, -0.7122, -0.7122,  0.0634]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(1.3770, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[-0.6924,  0.0734, -0.6924, -0.6924, -0.6924, -0.6924, -0.6924, -0.6924,\n",
      "         -0.6924, -0.6924, -0.6924,  0.0734]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(1.3375, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[-0.6726,  0.0832, -0.6726, -0.6726, -0.6726, -0.6726, -0.6726, -0.6726,\n",
      "         -0.6726, -0.6726, -0.6726,  0.0832]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(1.2989, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[-0.6529,  0.0931, -0.6529, -0.6529, -0.6529, -0.6529, -0.6529, -0.6529,\n",
      "         -0.6529, -0.6529, -0.6529,  0.0931]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(1.2610, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[-0.6333,  0.1029, -0.6333, -0.6333, -0.6333, -0.6333, -0.6333, -0.6333,\n",
      "         -0.6333, -0.6333, -0.6333,  0.1029]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(1.2239, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[-0.6138,  0.1127, -0.6138, -0.6138, -0.6138, -0.6138, -0.6138, -0.6138,\n",
      "         -0.6138, -0.6138, -0.6138,  0.1127]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(1.1876, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[-0.5943,  0.1224, -0.5943, -0.5943, -0.5943, -0.5943, -0.5943, -0.5943,\n",
      "         -0.5943, -0.5943, -0.5943,  0.1224]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(1.1522, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[-0.5749,  0.1321, -0.5749, -0.5749, -0.5749, -0.5749, -0.5749, -0.5749,\n",
      "         -0.5749, -0.5749, -0.5749,  0.1321]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(1.1175, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[-0.5556,  0.1418, -0.5556, -0.5556, -0.5556, -0.5556, -0.5556, -0.5556,\n",
      "         -0.5556, -0.5556, -0.5556,  0.1418]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(1.0837, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[-0.5364,  0.1514, -0.5364, -0.5364, -0.5364, -0.5364, -0.5364, -0.5364,\n",
      "         -0.5364, -0.5364, -0.5364,  0.1514]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(1.0507, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[-0.5173,  0.1610, -0.5173, -0.5173, -0.5173, -0.5173, -0.5173, -0.5173,\n",
      "         -0.5173, -0.5173, -0.5173,  0.1610]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(1.0185, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[-0.4983,  0.1705, -0.4983, -0.4983, -0.4983, -0.4983, -0.4983, -0.4983,\n",
      "         -0.4983, -0.4983, -0.4983,  0.1705]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.9871, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[-0.4794,  0.1799, -0.4794, -0.4794, -0.4794, -0.4794, -0.4794, -0.4794,\n",
      "         -0.4794, -0.4794, -0.4794,  0.1799]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.9566, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[-0.4607,  0.1893, -0.4607, -0.4607, -0.4607, -0.4607, -0.4607, -0.4607,\n",
      "         -0.4607, -0.4607, -0.4607,  0.1893]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.9268, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[-0.4421,  0.1987, -0.4421, -0.4421, -0.4421, -0.4421, -0.4421, -0.4421,\n",
      "         -0.4421, -0.4421, -0.4421,  0.1987]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.8979, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[-0.4236,  0.2079, -0.4236, -0.4236, -0.4236, -0.4236, -0.4236, -0.4236,\n",
      "         -0.4236, -0.4236, -0.4236,  0.2079]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.8698, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[-0.4052,  0.2171, -0.4052, -0.4052, -0.4052, -0.4052, -0.4052, -0.4052,\n",
      "         -0.4052, -0.4052, -0.4052,  0.2171]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.8425, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[-0.3871,  0.2263, -0.3871, -0.3871, -0.3871, -0.3871, -0.3871, -0.3871,\n",
      "         -0.3871, -0.3871, -0.3871,  0.2263]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.8160, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[-0.3690,  0.2353, -0.3690, -0.3690, -0.3690, -0.3690, -0.3690, -0.3690,\n",
      "         -0.3690, -0.3690, -0.3690,  0.2353]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.7903, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[-0.3511,  0.2443, -0.3511, -0.3511, -0.3511, -0.3511, -0.3511, -0.3511,\n",
      "         -0.3511, -0.3511, -0.3511,  0.2443]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.7654, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[-0.3334,  0.2532, -0.3334, -0.3334, -0.3334, -0.3334, -0.3334, -0.3334,\n",
      "         -0.3334, -0.3334, -0.3334,  0.2532]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.7412, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[-0.3159,  0.2620, -0.3159, -0.3159, -0.3159, -0.3159, -0.3159, -0.3159,\n",
      "         -0.3159, -0.3159, -0.3159,  0.2620]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.7178, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[-0.2985,  0.2708, -0.2985, -0.2985, -0.2985, -0.2985, -0.2985, -0.2985,\n",
      "         -0.2985, -0.2985, -0.2985,  0.2708]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.6952, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[-0.2813,  0.2794, -0.2813, -0.2813, -0.2813, -0.2813, -0.2813, -0.2813,\n",
      "         -0.2813, -0.2813, -0.2813,  0.2794]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.6733, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[-0.2643,  0.2880, -0.2643, -0.2643, -0.2643, -0.2643, -0.2643, -0.2643,\n",
      "         -0.2643, -0.2643, -0.2643,  0.2880]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.6522, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[-0.2474,  0.2964, -0.2474, -0.2474, -0.2474, -0.2474, -0.2474, -0.2474,\n",
      "         -0.2474, -0.2474, -0.2474,  0.2964]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.6318, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[-0.2308,  0.3048, -0.2308, -0.2308, -0.2308, -0.2308, -0.2308, -0.2308,\n",
      "         -0.2308, -0.2308, -0.2308,  0.3048]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.6121, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[-0.2144,  0.3131, -0.2144, -0.2144, -0.2144, -0.2144, -0.2144, -0.2144,\n",
      "         -0.2144, -0.2144, -0.2144,  0.3131]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.5932, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[-0.1981,  0.3213, -0.1981, -0.1981, -0.1981, -0.1981, -0.1981, -0.1981,\n",
      "         -0.1981, -0.1981, -0.1981,  0.3213]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.5749, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[-0.1821,  0.3294, -0.1821, -0.1821, -0.1821, -0.1821, -0.1821, -0.1821,\n",
      "         -0.1821, -0.1821, -0.1821,  0.3294]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.5573, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[-0.1662,  0.3374, -0.1662, -0.1662, -0.1662, -0.1662, -0.1662, -0.1662,\n",
      "         -0.1662, -0.1662, -0.1662,  0.3374]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.5404, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[-0.1506,  0.3453, -0.1506, -0.1506, -0.1506, -0.1506, -0.1506, -0.1506,\n",
      "         -0.1506, -0.1506, -0.1506,  0.3453]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.5241, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[-0.1352,  0.3531, -0.1352, -0.1352, -0.1352, -0.1352, -0.1352, -0.1352,\n",
      "         -0.1352, -0.1352, -0.1352,  0.3531]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.5084, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[-0.1200,  0.3608, -0.1200, -0.1200, -0.1200, -0.1200, -0.1200, -0.1200,\n",
      "         -0.1200, -0.1200, -0.1200,  0.3608]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.4934, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[-0.1050,  0.3684, -0.1050, -0.1050, -0.1050, -0.1050, -0.1050, -0.1050,\n",
      "         -0.1050, -0.1050, -0.1050,  0.3684]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.4790, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[-0.0903,  0.3759, -0.0903, -0.0903, -0.0903, -0.0903, -0.0903, -0.0903,\n",
      "         -0.0903, -0.0903, -0.0903,  0.3759]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.4652, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[-0.0757,  0.3833, -0.0757, -0.0757, -0.0757, -0.0757, -0.0757, -0.0757,\n",
      "         -0.0757, -0.0757, -0.0757,  0.3833]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.4520, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[-0.0614,  0.3905, -0.0614, -0.0614, -0.0614, -0.0614, -0.0614, -0.0614,\n",
      "         -0.0614, -0.0614, -0.0614,  0.3905]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.4393, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[-0.0473,  0.3977, -0.0473, -0.0473, -0.0473, -0.0473, -0.0473, -0.0473,\n",
      "         -0.0473, -0.0473, -0.0473,  0.3977]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.4272, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[-0.0335,  0.4047, -0.0335, -0.0335, -0.0335, -0.0335, -0.0335, -0.0335,\n",
      "         -0.0335, -0.0335, -0.0335,  0.4047]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.4156, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[-0.0199,  0.4117, -0.0199, -0.0199, -0.0199, -0.0199, -0.0199, -0.0199,\n",
      "         -0.0199, -0.0199, -0.0199,  0.4117]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.4046, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[-0.0065,  0.4185, -0.0065, -0.0065, -0.0065, -0.0065, -0.0065, -0.0065,\n",
      "         -0.0065, -0.0065, -0.0065,  0.4185]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.3940, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.0067, 0.4252, 0.0067, 0.0067, 0.0067, 0.0067, 0.0067, 0.0067, 0.0067,\n",
      "         0.0067, 0.0067, 0.4252]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.3840, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.0196, 0.4319, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196, 0.0196,\n",
      "         0.0196, 0.0196, 0.4319]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.3744, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.0323, 0.4384, 0.0323, 0.0323, 0.0323, 0.0323, 0.0323, 0.0323, 0.0323,\n",
      "         0.0323, 0.0323, 0.4384]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.3652, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.0447, 0.4447, 0.0447, 0.0447, 0.0447, 0.0447, 0.0447, 0.0447, 0.0447,\n",
      "         0.0447, 0.0447, 0.4447]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.3566, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.0570, 0.4510, 0.0570, 0.0570, 0.0570, 0.0570, 0.0570, 0.0570, 0.0570,\n",
      "         0.0570, 0.0570, 0.4510]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.3483, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.0689, 0.4572, 0.0689, 0.0689, 0.0689, 0.0689, 0.0689, 0.0689, 0.0689,\n",
      "         0.0689, 0.0689, 0.4572]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.3405, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.0807, 0.4632, 0.0807, 0.0807, 0.0807, 0.0807, 0.0807, 0.0807, 0.0807,\n",
      "         0.0807, 0.0807, 0.4632]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.3330, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.0922, 0.4692, 0.0922, 0.0922, 0.0922, 0.0922, 0.0922, 0.0922, 0.0922,\n",
      "         0.0922, 0.0922, 0.4692]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.3259, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.1034, 0.4750, 0.1034, 0.1034, 0.1034, 0.1034, 0.1034, 0.1034, 0.1034,\n",
      "         0.1034, 0.1034, 0.4750]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.3192, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.1144, 0.4807, 0.1144, 0.1144, 0.1144, 0.1144, 0.1144, 0.1144, 0.1144,\n",
      "         0.1144, 0.1144, 0.4807]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.3129, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.1252, 0.4863, 0.1252, 0.1252, 0.1252, 0.1252, 0.1252, 0.1252, 0.1252,\n",
      "         0.1252, 0.1252, 0.4863]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.3069, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.1358, 0.4918, 0.1358, 0.1358, 0.1358, 0.1358, 0.1358, 0.1358, 0.1358,\n",
      "         0.1358, 0.1358, 0.4918]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.3012, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.1461, 0.4972, 0.1461, 0.1461, 0.1461, 0.1461, 0.1461, 0.1461, 0.1461,\n",
      "         0.1461, 0.1461, 0.4972]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2959, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.1561, 0.5025, 0.1561, 0.1561, 0.1561, 0.1561, 0.1561, 0.1561, 0.1561,\n",
      "         0.1561, 0.1561, 0.5025]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2908, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.1660, 0.5076, 0.1660, 0.1660, 0.1660, 0.1660, 0.1660, 0.1660, 0.1660,\n",
      "         0.1660, 0.1660, 0.5076]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2860, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.1756, 0.5127, 0.1756, 0.1756, 0.1756, 0.1756, 0.1756, 0.1756, 0.1756,\n",
      "         0.1756, 0.1756, 0.5127]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2816, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.1850, 0.5176, 0.1850, 0.1850, 0.1850, 0.1850, 0.1850, 0.1850, 0.1850,\n",
      "         0.1850, 0.1850, 0.5176]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2773, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.1941, 0.5224, 0.1941, 0.1941, 0.1941, 0.1941, 0.1941, 0.1941, 0.1941,\n",
      "         0.1941, 0.1941, 0.5224]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2733, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.2030, 0.5271, 0.2030, 0.2030, 0.2030, 0.2030, 0.2030, 0.2030, 0.2030,\n",
      "         0.2030, 0.2030, 0.5271]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2696, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.2117, 0.5318, 0.2117, 0.2117, 0.2117, 0.2117, 0.2117, 0.2117, 0.2117,\n",
      "         0.2117, 0.2117, 0.5318]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2661, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.2202, 0.5363, 0.2202, 0.2202, 0.2202, 0.2202, 0.2202, 0.2202, 0.2202,\n",
      "         0.2202, 0.2202, 0.5363]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2628, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.2284, 0.5407, 0.2284, 0.2284, 0.2284, 0.2284, 0.2284, 0.2284, 0.2284,\n",
      "         0.2284, 0.2284, 0.5407]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2597, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.2364, 0.5450, 0.2364, 0.2364, 0.2364, 0.2364, 0.2364, 0.2364, 0.2364,\n",
      "         0.2364, 0.2364, 0.5450]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2568, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.2442, 0.5492, 0.2442, 0.2442, 0.2442, 0.2442, 0.2442, 0.2442, 0.2442,\n",
      "         0.2442, 0.2442, 0.5492]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2541, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.2518, 0.5533, 0.2518, 0.2518, 0.2518, 0.2518, 0.2518, 0.2518, 0.2518,\n",
      "         0.2518, 0.2518, 0.5533]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2516, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.2592, 0.5573, 0.2592, 0.2592, 0.2592, 0.2592, 0.2592, 0.2592, 0.2592,\n",
      "         0.2592, 0.2592, 0.5573]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2492, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.2663, 0.5612, 0.2663, 0.2663, 0.2663, 0.2663, 0.2663, 0.2663, 0.2663,\n",
      "         0.2663, 0.2663, 0.5612]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2470, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.2733, 0.5650, 0.2733, 0.2733, 0.2733, 0.2733, 0.2733, 0.2733, 0.2733,\n",
      "         0.2733, 0.2733, 0.5650]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2449, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.2800, 0.5687, 0.2800, 0.2800, 0.2800, 0.2800, 0.2800, 0.2800, 0.2800,\n",
      "         0.2800, 0.2800, 0.5687]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2430, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.2865, 0.5723, 0.2865, 0.2865, 0.2865, 0.2865, 0.2865, 0.2865, 0.2865,\n",
      "         0.2865, 0.2865, 0.5723]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2412, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.2929, 0.5758, 0.2929, 0.2929, 0.2929, 0.2929, 0.2929, 0.2929, 0.2929,\n",
      "         0.2929, 0.2929, 0.5758]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2396, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.2990, 0.5792, 0.2990, 0.2990, 0.2990, 0.2990, 0.2990, 0.2990, 0.2990,\n",
      "         0.2990, 0.2990, 0.5792]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2380, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.3049, 0.5825, 0.3049, 0.3049, 0.3049, 0.3049, 0.3049, 0.3049, 0.3049,\n",
      "         0.3049, 0.3049, 0.5825]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2366, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.3107, 0.5858, 0.3107, 0.3107, 0.3107, 0.3107, 0.3107, 0.3107, 0.3107,\n",
      "         0.3107, 0.3107, 0.5858]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2352, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.3163, 0.5889, 0.3163, 0.3163, 0.3163, 0.3163, 0.3163, 0.3163, 0.3163,\n",
      "         0.3163, 0.3163, 0.5889]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2340, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.3216, 0.5920, 0.3216, 0.3216, 0.3216, 0.3216, 0.3216, 0.3216, 0.3216,\n",
      "         0.3216, 0.3216, 0.5920]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2329, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.3268, 0.5950, 0.3268, 0.3268, 0.3268, 0.3268, 0.3268, 0.3268, 0.3268,\n",
      "         0.3268, 0.3268, 0.5950]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2318, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.3318, 0.5979, 0.3318, 0.3318, 0.3318, 0.3318, 0.3318, 0.3318, 0.3318,\n",
      "         0.3318, 0.3318, 0.5979]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2308, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.3367, 0.6007, 0.3367, 0.3367, 0.3367, 0.3367, 0.3367, 0.3367, 0.3367,\n",
      "         0.3367, 0.3367, 0.6007]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2299, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.3413, 0.6034, 0.3413, 0.3413, 0.3413, 0.3413, 0.3413, 0.3413, 0.3413,\n",
      "         0.3413, 0.3413, 0.6034]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2291, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.3458, 0.6061, 0.3458, 0.3458, 0.3458, 0.3458, 0.3458, 0.3458, 0.3458,\n",
      "         0.3458, 0.3458, 0.6061]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2283, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.3502, 0.6087, 0.3502, 0.3502, 0.3502, 0.3502, 0.3502, 0.3502, 0.3502,\n",
      "         0.3502, 0.3502, 0.6087]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2276, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.3544, 0.6112, 0.3544, 0.3544, 0.3544, 0.3544, 0.3544, 0.3544, 0.3544,\n",
      "         0.3544, 0.3544, 0.6112]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2269, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.3584, 0.6136, 0.3584, 0.3584, 0.3584, 0.3584, 0.3584, 0.3584, 0.3584,\n",
      "         0.3584, 0.3584, 0.6136]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2263, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.3622, 0.6160, 0.3622, 0.3622, 0.3622, 0.3622, 0.3622, 0.3622, 0.3622,\n",
      "         0.3622, 0.3622, 0.6160]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2258, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.3659, 0.6183, 0.3659, 0.3659, 0.3659, 0.3659, 0.3659, 0.3659, 0.3659,\n",
      "         0.3659, 0.3659, 0.6183]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2252, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.3695, 0.6205, 0.3695, 0.3695, 0.3695, 0.3695, 0.3695, 0.3695, 0.3695,\n",
      "         0.3695, 0.3695, 0.6205]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2248, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.3729, 0.6227, 0.3729, 0.3729, 0.3729, 0.3729, 0.3729, 0.3729, 0.3729,\n",
      "         0.3729, 0.3729, 0.6227]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2243, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.3762, 0.6248, 0.3762, 0.3762, 0.3762, 0.3762, 0.3762, 0.3762, 0.3762,\n",
      "         0.3762, 0.3762, 0.6248]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2239, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.3794, 0.6268, 0.3794, 0.3794, 0.3794, 0.3794, 0.3794, 0.3794, 0.3794,\n",
      "         0.3794, 0.3794, 0.6268]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2236, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.3824, 0.6288, 0.3824, 0.3824, 0.3824, 0.3824, 0.3824, 0.3824, 0.3824,\n",
      "         0.3824, 0.3824, 0.6288]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2232, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.3852, 0.6307, 0.3852, 0.3852, 0.3852, 0.3852, 0.3852, 0.3852, 0.3852,\n",
      "         0.3852, 0.3852, 0.6307]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2229, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.3880, 0.6325, 0.3880, 0.3880, 0.3880, 0.3880, 0.3880, 0.3880, 0.3880,\n",
      "         0.3880, 0.3880, 0.6325]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2226, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.3906, 0.6343, 0.3906, 0.3906, 0.3906, 0.3906, 0.3906, 0.3906, 0.3906,\n",
      "         0.3906, 0.3906, 0.6343]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2224, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.3932, 0.6361, 0.3932, 0.3932, 0.3932, 0.3932, 0.3932, 0.3932, 0.3932,\n",
      "         0.3932, 0.3932, 0.6361]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2221, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.3956, 0.6378, 0.3956, 0.3956, 0.3956, 0.3956, 0.3956, 0.3956, 0.3956,\n",
      "         0.3956, 0.3956, 0.6378]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2219, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.3979, 0.6394, 0.3979, 0.3979, 0.3979, 0.3979, 0.3979, 0.3979, 0.3979,\n",
      "         0.3979, 0.3979, 0.6394]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2217, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4000, 0.6410, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000,\n",
      "         0.4000, 0.4000, 0.6410]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2215, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4021, 0.6425, 0.4021, 0.4021, 0.4021, 0.4021, 0.4021, 0.4021, 0.4021,\n",
      "         0.4021, 0.4021, 0.6425]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2213, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4041, 0.6440, 0.4041, 0.4041, 0.4041, 0.4041, 0.4041, 0.4041, 0.4041,\n",
      "         0.4041, 0.4041, 0.6440]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2211, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4060, 0.6455, 0.4060, 0.4060, 0.4060, 0.4060, 0.4060, 0.4060, 0.4060,\n",
      "         0.4060, 0.4060, 0.6455]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2210, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4077, 0.6469, 0.4077, 0.4077, 0.4077, 0.4077, 0.4077, 0.4077, 0.4077,\n",
      "         0.4077, 0.4077, 0.6469]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2208, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4094, 0.6483, 0.4094, 0.4094, 0.4094, 0.4094, 0.4094, 0.4094, 0.4094,\n",
      "         0.4094, 0.4094, 0.6483]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2207, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4110, 0.6496, 0.4110, 0.4110, 0.4110, 0.4110, 0.4110, 0.4110, 0.4110,\n",
      "         0.4110, 0.4110, 0.6496]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2206, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4126, 0.6509, 0.4126, 0.4126, 0.4126, 0.4126, 0.4126, 0.4126, 0.4126,\n",
      "         0.4126, 0.4126, 0.6509]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2204, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4140, 0.6521, 0.4140, 0.4140, 0.4140, 0.4140, 0.4140, 0.4140, 0.4140,\n",
      "         0.4140, 0.4140, 0.6521]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2203, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4154, 0.6533, 0.4154, 0.4154, 0.4154, 0.4154, 0.4154, 0.4154, 0.4154,\n",
      "         0.4154, 0.4154, 0.6533]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2202, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4166, 0.6545, 0.4166, 0.4166, 0.4166, 0.4166, 0.4166, 0.4166, 0.4166,\n",
      "         0.4166, 0.4166, 0.6545]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2201, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4178, 0.6557, 0.4178, 0.4178, 0.4178, 0.4178, 0.4178, 0.4178, 0.4178,\n",
      "         0.4178, 0.4178, 0.6557]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2200, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4190, 0.6568, 0.4190, 0.4190, 0.4190, 0.4190, 0.4190, 0.4190, 0.4190,\n",
      "         0.4190, 0.4190, 0.6568]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2199, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4200, 0.6578, 0.4200, 0.4200, 0.4200, 0.4200, 0.4200, 0.4200, 0.4200,\n",
      "         0.4200, 0.4200, 0.6578]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2198, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4210, 0.6589, 0.4210, 0.4210, 0.4210, 0.4210, 0.4210, 0.4210, 0.4210,\n",
      "         0.4210, 0.4210, 0.6589]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2198, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4220, 0.6599, 0.4220, 0.4220, 0.4220, 0.4220, 0.4220, 0.4220, 0.4220,\n",
      "         0.4220, 0.4220, 0.6599]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2197, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4229, 0.6609, 0.4229, 0.4229, 0.4229, 0.4229, 0.4229, 0.4229, 0.4229,\n",
      "         0.4229, 0.4229, 0.6609]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2196, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4237, 0.6619, 0.4237, 0.4237, 0.4237, 0.4237, 0.4237, 0.4237, 0.4237,\n",
      "         0.4237, 0.4237, 0.6619]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2195, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4244, 0.6628, 0.4244, 0.4244, 0.4244, 0.4244, 0.4244, 0.4244, 0.4244,\n",
      "         0.4244, 0.4244, 0.6628]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2194, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4252, 0.6638, 0.4252, 0.4252, 0.4252, 0.4252, 0.4252, 0.4252, 0.4252,\n",
      "         0.4252, 0.4252, 0.6638]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2194, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4258, 0.6647, 0.4258, 0.4258, 0.4258, 0.4258, 0.4258, 0.4258, 0.4258,\n",
      "         0.4258, 0.4258, 0.6647]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2193, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4264, 0.6655, 0.4264, 0.4264, 0.4264, 0.4264, 0.4264, 0.4264, 0.4264,\n",
      "         0.4264, 0.4264, 0.6655]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2192, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4270, 0.6664, 0.4270, 0.4270, 0.4270, 0.4270, 0.4270, 0.4270, 0.4270,\n",
      "         0.4270, 0.4270, 0.6664]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2192, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4275, 0.6672, 0.4275, 0.4275, 0.4275, 0.4275, 0.4275, 0.4275, 0.4275,\n",
      "         0.4275, 0.4275, 0.6672]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2191, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4280, 0.6680, 0.4280, 0.4280, 0.4280, 0.4280, 0.4280, 0.4280, 0.4280,\n",
      "         0.4280, 0.4280, 0.6680]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2190, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4285, 0.6689, 0.4285, 0.4285, 0.4285, 0.4285, 0.4285, 0.4285, 0.4285,\n",
      "         0.4285, 0.4285, 0.6689]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2190, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4289, 0.6696, 0.4289, 0.4289, 0.4289, 0.4289, 0.4289, 0.4289, 0.4289,\n",
      "         0.4289, 0.4289, 0.6696]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2189, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4293, 0.6704, 0.4293, 0.4293, 0.4293, 0.4293, 0.4293, 0.4293, 0.4293,\n",
      "         0.4293, 0.4293, 0.6704]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2188, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4296, 0.6712, 0.4296, 0.4296, 0.4296, 0.4296, 0.4296, 0.4296, 0.4296,\n",
      "         0.4296, 0.4296, 0.6712]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2188, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4299, 0.6719, 0.4299, 0.4299, 0.4299, 0.4299, 0.4299, 0.4299, 0.4299,\n",
      "         0.4299, 0.4299, 0.6719]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2187, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4302, 0.6726, 0.4302, 0.4302, 0.4302, 0.4302, 0.4302, 0.4302, 0.4302,\n",
      "         0.4302, 0.4302, 0.6726]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2186, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4304, 0.6734, 0.4304, 0.4304, 0.4304, 0.4304, 0.4304, 0.4304, 0.4304,\n",
      "         0.4304, 0.4304, 0.6734]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2186, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4307, 0.6741, 0.4307, 0.4307, 0.4307, 0.4307, 0.4307, 0.4307, 0.4307,\n",
      "         0.4307, 0.4307, 0.6741]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2185, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4309, 0.6748, 0.4309, 0.4309, 0.4309, 0.4309, 0.4309, 0.4309, 0.4309,\n",
      "         0.4309, 0.4309, 0.6748]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2184, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4310, 0.6754, 0.4310, 0.4310, 0.4310, 0.4310, 0.4310, 0.4310, 0.4310,\n",
      "         0.4310, 0.4310, 0.6754]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2184, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4312, 0.6761, 0.4312, 0.4312, 0.4312, 0.4312, 0.4312, 0.4312, 0.4312,\n",
      "         0.4312, 0.4312, 0.6761]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2183, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4313, 0.6768, 0.4313, 0.4313, 0.4313, 0.4313, 0.4313, 0.4313, 0.4313,\n",
      "         0.4313, 0.4313, 0.6768]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2182, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4314, 0.6774, 0.4314, 0.4314, 0.4314, 0.4314, 0.4314, 0.4314, 0.4314,\n",
      "         0.4314, 0.4314, 0.6774]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2182, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4315, 0.6781, 0.4315, 0.4315, 0.4315, 0.4315, 0.4315, 0.4315, 0.4315,\n",
      "         0.4315, 0.4315, 0.6781]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2181, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4316, 0.6787, 0.4316, 0.4316, 0.4316, 0.4316, 0.4316, 0.4316, 0.4316,\n",
      "         0.4316, 0.4316, 0.6787]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2180, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4316, 0.6794, 0.4316, 0.4316, 0.4316, 0.4316, 0.4316, 0.4316, 0.4316,\n",
      "         0.4316, 0.4316, 0.6794]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2180, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4317, 0.6800, 0.4317, 0.4317, 0.4317, 0.4317, 0.4317, 0.4317, 0.4317,\n",
      "         0.4317, 0.4317, 0.6800]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2179, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4317, 0.6806, 0.4317, 0.4317, 0.4317, 0.4317, 0.4317, 0.4317, 0.4317,\n",
      "         0.4317, 0.4317, 0.6806]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2178, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4317, 0.6813, 0.4317, 0.4317, 0.4317, 0.4317, 0.4317, 0.4317, 0.4317,\n",
      "         0.4317, 0.4317, 0.6813]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2178, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4317, 0.6819, 0.4317, 0.4317, 0.4317, 0.4317, 0.4317, 0.4317, 0.4317,\n",
      "         0.4317, 0.4317, 0.6819]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2177, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4317, 0.6825, 0.4317, 0.4317, 0.4317, 0.4317, 0.4317, 0.4317, 0.4317,\n",
      "         0.4317, 0.4317, 0.6825]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2176, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4317, 0.6831, 0.4317, 0.4317, 0.4317, 0.4317, 0.4317, 0.4317, 0.4317,\n",
      "         0.4317, 0.4317, 0.6831]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2176, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4317, 0.6837, 0.4317, 0.4317, 0.4317, 0.4317, 0.4317, 0.4317, 0.4317,\n",
      "         0.4317, 0.4317, 0.6837]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2175, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4316, 0.6843, 0.4316, 0.4316, 0.4316, 0.4316, 0.4316, 0.4316, 0.4316,\n",
      "         0.4316, 0.4316, 0.6843]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2174, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4316, 0.6849, 0.4316, 0.4316, 0.4316, 0.4316, 0.4316, 0.4316, 0.4316,\n",
      "         0.4316, 0.4316, 0.6849]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2174, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4315, 0.6855, 0.4315, 0.4315, 0.4315, 0.4315, 0.4315, 0.4315, 0.4315,\n",
      "         0.4315, 0.4315, 0.6855]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2173, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4315, 0.6861, 0.4315, 0.4315, 0.4315, 0.4315, 0.4315, 0.4315, 0.4315,\n",
      "         0.4315, 0.4315, 0.6861]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2172, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4314, 0.6867, 0.4314, 0.4314, 0.4314, 0.4314, 0.4314, 0.4314, 0.4314,\n",
      "         0.4314, 0.4314, 0.6867]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2172, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4314, 0.6873, 0.4314, 0.4314, 0.4314, 0.4314, 0.4314, 0.4314, 0.4314,\n",
      "         0.4314, 0.4314, 0.6873]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2171, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4313, 0.6879, 0.4313, 0.4313, 0.4313, 0.4313, 0.4313, 0.4313, 0.4313,\n",
      "         0.4313, 0.4313, 0.6879]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2171, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4312, 0.6884, 0.4312, 0.4312, 0.4312, 0.4312, 0.4312, 0.4312, 0.4312,\n",
      "         0.4312, 0.4312, 0.6884]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2170, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4311, 0.6890, 0.4311, 0.4311, 0.4311, 0.4311, 0.4311, 0.4311, 0.4311,\n",
      "         0.4311, 0.4311, 0.6890]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2169, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4310, 0.6896, 0.4310, 0.4310, 0.4310, 0.4310, 0.4310, 0.4310, 0.4310,\n",
      "         0.4310, 0.4310, 0.6896]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2169, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4309, 0.6902, 0.4309, 0.4309, 0.4309, 0.4309, 0.4309, 0.4309, 0.4309,\n",
      "         0.4309, 0.4309, 0.6902]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2168, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4308, 0.6908, 0.4308, 0.4308, 0.4308, 0.4308, 0.4308, 0.4308, 0.4308,\n",
      "         0.4308, 0.4308, 0.6908]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2167, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4307, 0.6914, 0.4307, 0.4307, 0.4307, 0.4307, 0.4307, 0.4307, 0.4307,\n",
      "         0.4307, 0.4307, 0.6914]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2167, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4307, 0.6920, 0.4307, 0.4307, 0.4307, 0.4307, 0.4307, 0.4307, 0.4307,\n",
      "         0.4307, 0.4307, 0.6920]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2166, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4306, 0.6926, 0.4306, 0.4306, 0.4306, 0.4306, 0.4306, 0.4306, 0.4306,\n",
      "         0.4306, 0.4306, 0.6926]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2165, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4305, 0.6931, 0.4305, 0.4305, 0.4305, 0.4305, 0.4305, 0.4305, 0.4305,\n",
      "         0.4305, 0.4305, 0.6931]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2165, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4304, 0.6937, 0.4304, 0.4304, 0.4304, 0.4304, 0.4304, 0.4304, 0.4304,\n",
      "         0.4304, 0.4304, 0.6937]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2164, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4303, 0.6943, 0.4303, 0.4303, 0.4303, 0.4303, 0.4303, 0.4303, 0.4303,\n",
      "         0.4303, 0.4303, 0.6943]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2163, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4302, 0.6949, 0.4302, 0.4302, 0.4302, 0.4302, 0.4302, 0.4302, 0.4302,\n",
      "         0.4302, 0.4302, 0.6949]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2163, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4301, 0.6955, 0.4301, 0.4301, 0.4301, 0.4301, 0.4301, 0.4301, 0.4301,\n",
      "         0.4301, 0.4301, 0.6955]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2162, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4300, 0.6961, 0.4300, 0.4300, 0.4300, 0.4300, 0.4300, 0.4300, 0.4300,\n",
      "         0.4300, 0.4300, 0.6961]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2161, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4298, 0.6967, 0.4298, 0.4298, 0.4298, 0.4298, 0.4298, 0.4298, 0.4298,\n",
      "         0.4298, 0.4298, 0.6967]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2161, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4297, 0.6973, 0.4297, 0.4297, 0.4297, 0.4297, 0.4297, 0.4297, 0.4297,\n",
      "         0.4297, 0.4297, 0.6973]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2160, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4296, 0.6978, 0.4296, 0.4296, 0.4296, 0.4296, 0.4296, 0.4296, 0.4296,\n",
      "         0.4296, 0.4296, 0.6978]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2159, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4295, 0.6984, 0.4295, 0.4295, 0.4295, 0.4295, 0.4295, 0.4295, 0.4295,\n",
      "         0.4295, 0.4295, 0.6984]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2159, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4294, 0.6990, 0.4294, 0.4294, 0.4294, 0.4294, 0.4294, 0.4294, 0.4294,\n",
      "         0.4294, 0.4294, 0.6990]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2158, grad_fn=<MseLossBackward0>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4293, 0.6996, 0.4293, 0.4293, 0.4293, 0.4293, 0.4293, 0.4293, 0.4293,\n",
      "         0.4293, 0.4293, 0.6996]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2158, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4293, 0.7002, 0.4293, 0.4293, 0.4293, 0.4293, 0.4293, 0.4293, 0.4293,\n",
      "         0.4293, 0.4293, 0.7002]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2157, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4292, 0.7008, 0.4292, 0.4292, 0.4292, 0.4292, 0.4292, 0.4292, 0.4292,\n",
      "         0.4292, 0.4292, 0.7008]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2156, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4291, 0.7014, 0.4291, 0.4291, 0.4291, 0.4291, 0.4291, 0.4291, 0.4291,\n",
      "         0.4291, 0.4291, 0.7014]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2156, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4290, 0.7020, 0.4290, 0.4290, 0.4290, 0.4290, 0.4290, 0.4290, 0.4290,\n",
      "         0.4290, 0.4290, 0.7020]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2155, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4289, 0.7026, 0.4289, 0.4289, 0.4289, 0.4289, 0.4289, 0.4289, 0.4289,\n",
      "         0.4289, 0.4289, 0.7026]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2154, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4288, 0.7032, 0.4288, 0.4288, 0.4288, 0.4288, 0.4288, 0.4288, 0.4288,\n",
      "         0.4288, 0.4288, 0.7032]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2154, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4287, 0.7038, 0.4287, 0.4287, 0.4287, 0.4287, 0.4287, 0.4287, 0.4287,\n",
      "         0.4287, 0.4287, 0.7038]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2153, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4286, 0.7044, 0.4286, 0.4286, 0.4286, 0.4286, 0.4286, 0.4286, 0.4286,\n",
      "         0.4286, 0.4286, 0.7044]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2152, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4285, 0.7050, 0.4285, 0.4285, 0.4285, 0.4285, 0.4285, 0.4285, 0.4285,\n",
      "         0.4285, 0.4285, 0.7050]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2152, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4284, 0.7056, 0.4284, 0.4284, 0.4284, 0.4284, 0.4284, 0.4284, 0.4284,\n",
      "         0.4284, 0.4284, 0.7056]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2151, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4283, 0.7062, 0.4283, 0.4283, 0.4283, 0.4283, 0.4283, 0.4283, 0.4283,\n",
      "         0.4283, 0.4283, 0.7062]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2151, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4282, 0.7068, 0.4282, 0.4282, 0.4282, 0.4282, 0.4282, 0.4282, 0.4282,\n",
      "         0.4282, 0.4282, 0.7068]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2150, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4282, 0.7074, 0.4282, 0.4282, 0.4282, 0.4282, 0.4282, 0.4282, 0.4282,\n",
      "         0.4282, 0.4282, 0.7074]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2149, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4281, 0.7081, 0.4281, 0.4281, 0.4281, 0.4281, 0.4281, 0.4281, 0.4281,\n",
      "         0.4281, 0.4281, 0.7081]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2149, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4280, 0.7087, 0.4280, 0.4280, 0.4280, 0.4280, 0.4280, 0.4280, 0.4280,\n",
      "         0.4280, 0.4280, 0.7087]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2148, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4279, 0.7093, 0.4279, 0.4279, 0.4279, 0.4279, 0.4279, 0.4279, 0.4279,\n",
      "         0.4279, 0.4279, 0.7093]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2147, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4278, 0.7099, 0.4278, 0.4278, 0.4278, 0.4278, 0.4278, 0.4278, 0.4278,\n",
      "         0.4278, 0.4278, 0.7099]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2147, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4278, 0.7105, 0.4278, 0.4278, 0.4278, 0.4278, 0.4278, 0.4278, 0.4278,\n",
      "         0.4278, 0.4278, 0.7105]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2146, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4277, 0.7111, 0.4277, 0.4277, 0.4277, 0.4277, 0.4277, 0.4277, 0.4277,\n",
      "         0.4277, 0.4277, 0.7111]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2145, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4276, 0.7117, 0.4276, 0.4276, 0.4276, 0.4276, 0.4276, 0.4276, 0.4276,\n",
      "         0.4276, 0.4276, 0.7117]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2145, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4275, 0.7123, 0.4275, 0.4275, 0.4275, 0.4275, 0.4275, 0.4275, 0.4275,\n",
      "         0.4275, 0.4275, 0.7123]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2144, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4275, 0.7130, 0.4275, 0.4275, 0.4275, 0.4275, 0.4275, 0.4275, 0.4275,\n",
      "         0.4275, 0.4275, 0.7130]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2144, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4274, 0.7136, 0.4274, 0.4274, 0.4274, 0.4274, 0.4274, 0.4274, 0.4274,\n",
      "         0.4274, 0.4274, 0.7136]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2143, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4273, 0.7142, 0.4273, 0.4273, 0.4273, 0.4273, 0.4273, 0.4273, 0.4273,\n",
      "         0.4273, 0.4273, 0.7142]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2142, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4272, 0.7148, 0.4272, 0.4272, 0.4272, 0.4272, 0.4272, 0.4272, 0.4272,\n",
      "         0.4272, 0.4272, 0.7148]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2142, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4272, 0.7154, 0.4272, 0.4272, 0.4272, 0.4272, 0.4272, 0.4272, 0.4272,\n",
      "         0.4272, 0.4272, 0.7154]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2141, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4271, 0.7161, 0.4271, 0.4271, 0.4271, 0.4271, 0.4271, 0.4271, 0.4271,\n",
      "         0.4271, 0.4271, 0.7161]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2140, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4270, 0.7167, 0.4270, 0.4270, 0.4270, 0.4270, 0.4270, 0.4270, 0.4270,\n",
      "         0.4270, 0.4270, 0.7167]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2140, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4270, 0.7173, 0.4270, 0.4270, 0.4270, 0.4270, 0.4270, 0.4270, 0.4270,\n",
      "         0.4270, 0.4270, 0.7173]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2139, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4269, 0.7179, 0.4269, 0.4269, 0.4269, 0.4269, 0.4269, 0.4269, 0.4269,\n",
      "         0.4269, 0.4269, 0.7179]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2139, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4268, 0.7186, 0.4268, 0.4268, 0.4268, 0.4268, 0.4268, 0.4268, 0.4268,\n",
      "         0.4268, 0.4268, 0.7186]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2138, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4268, 0.7192, 0.4268, 0.4268, 0.4268, 0.4268, 0.4268, 0.4268, 0.4268,\n",
      "         0.4268, 0.4268, 0.7192]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2137, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4267, 0.7198, 0.4267, 0.4267, 0.4267, 0.4267, 0.4267, 0.4267, 0.4267,\n",
      "         0.4267, 0.4267, 0.7198]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2137, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4266, 0.7204, 0.4266, 0.4266, 0.4266, 0.4266, 0.4266, 0.4266, 0.4266,\n",
      "         0.4266, 0.4266, 0.7204]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2136, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4266, 0.7211, 0.4266, 0.4266, 0.4266, 0.4266, 0.4266, 0.4266, 0.4266,\n",
      "         0.4266, 0.4266, 0.7211]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2136, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4265, 0.7217, 0.4265, 0.4265, 0.4265, 0.4265, 0.4265, 0.4265, 0.4265,\n",
      "         0.4265, 0.4265, 0.7217]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2135, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4264, 0.7223, 0.4264, 0.4264, 0.4264, 0.4264, 0.4264, 0.4264, 0.4264,\n",
      "         0.4264, 0.4264, 0.7223]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2134, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4264, 0.7229, 0.4264, 0.4264, 0.4264, 0.4264, 0.4264, 0.4264, 0.4264,\n",
      "         0.4264, 0.4264, 0.7229]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2134, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4263, 0.7236, 0.4263, 0.4263, 0.4263, 0.4263, 0.4263, 0.4263, 0.4263,\n",
      "         0.4263, 0.4263, 0.7236]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2133, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4262, 0.7242, 0.4262, 0.4262, 0.4262, 0.4262, 0.4262, 0.4262, 0.4262,\n",
      "         0.4262, 0.4262, 0.7242]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2133, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4262, 0.7248, 0.4262, 0.4262, 0.4262, 0.4262, 0.4262, 0.4262, 0.4262,\n",
      "         0.4262, 0.4262, 0.7248]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2132, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4261, 0.7255, 0.4261, 0.4261, 0.4261, 0.4261, 0.4261, 0.4261, 0.4261,\n",
      "         0.4261, 0.4261, 0.7255]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2131, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4261, 0.7261, 0.4261, 0.4261, 0.4261, 0.4261, 0.4261, 0.4261, 0.4261,\n",
      "         0.4261, 0.4261, 0.7261]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2131, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4260, 0.7267, 0.4260, 0.4260, 0.4260, 0.4260, 0.4260, 0.4260, 0.4260,\n",
      "         0.4260, 0.4260, 0.7267]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2130, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4259, 0.7273, 0.4259, 0.4259, 0.4259, 0.4259, 0.4259, 0.4259, 0.4259,\n",
      "         0.4259, 0.4259, 0.7273]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2130, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4259, 0.7280, 0.4259, 0.4259, 0.4259, 0.4259, 0.4259, 0.4259, 0.4259,\n",
      "         0.4259, 0.4259, 0.7280]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2129, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4258, 0.7286, 0.4258, 0.4258, 0.4258, 0.4258, 0.4258, 0.4258, 0.4258,\n",
      "         0.4258, 0.4258, 0.7286]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2128, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4258, 0.7292, 0.4258, 0.4258, 0.4258, 0.4258, 0.4258, 0.4258, 0.4258,\n",
      "         0.4258, 0.4258, 0.7292]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2128, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4257, 0.7299, 0.4257, 0.4257, 0.4257, 0.4257, 0.4257, 0.4257, 0.4257,\n",
      "         0.4257, 0.4257, 0.7299]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2127, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4256, 0.7305, 0.4256, 0.4256, 0.4256, 0.4256, 0.4256, 0.4256, 0.4256,\n",
      "         0.4256, 0.4256, 0.7305]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2127, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4256, 0.7311, 0.4256, 0.4256, 0.4256, 0.4256, 0.4256, 0.4256, 0.4256,\n",
      "         0.4256, 0.4256, 0.7311]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2126, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4255, 0.7318, 0.4255, 0.4255, 0.4255, 0.4255, 0.4255, 0.4255, 0.4255,\n",
      "         0.4255, 0.4255, 0.7318]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2125, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4255, 0.7324, 0.4255, 0.4255, 0.4255, 0.4255, 0.4255, 0.4255, 0.4255,\n",
      "         0.4255, 0.4255, 0.7324]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2125, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4254, 0.7330, 0.4254, 0.4254, 0.4254, 0.4254, 0.4254, 0.4254, 0.4254,\n",
      "         0.4254, 0.4254, 0.7330]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2124, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4253, 0.7337, 0.4253, 0.4253, 0.4253, 0.4253, 0.4253, 0.4253, 0.4253,\n",
      "         0.4253, 0.4253, 0.7337]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2124, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4253, 0.7343, 0.4253, 0.4253, 0.4253, 0.4253, 0.4253, 0.4253, 0.4253,\n",
      "         0.4253, 0.4253, 0.7343]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2123, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4252, 0.7349, 0.4252, 0.4252, 0.4252, 0.4252, 0.4252, 0.4252, 0.4252,\n",
      "         0.4252, 0.4252, 0.7349]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2122, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4252, 0.7356, 0.4252, 0.4252, 0.4252, 0.4252, 0.4252, 0.4252, 0.4252,\n",
      "         0.4252, 0.4252, 0.7356]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2122, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4251, 0.7362, 0.4251, 0.4251, 0.4251, 0.4251, 0.4251, 0.4251, 0.4251,\n",
      "         0.4251, 0.4251, 0.7362]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2121, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4251, 0.7368, 0.4251, 0.4251, 0.4251, 0.4251, 0.4251, 0.4251, 0.4251,\n",
      "         0.4251, 0.4251, 0.7368]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2121, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4250, 0.7375, 0.4250, 0.4250, 0.4250, 0.4250, 0.4250, 0.4250, 0.4250,\n",
      "         0.4250, 0.4250, 0.7375]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2120, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4249, 0.7381, 0.4249, 0.4249, 0.4249, 0.4249, 0.4249, 0.4249, 0.4249,\n",
      "         0.4249, 0.4249, 0.7381]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2120, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4249, 0.7387, 0.4249, 0.4249, 0.4249, 0.4249, 0.4249, 0.4249, 0.4249,\n",
      "         0.4249, 0.4249, 0.7387]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2119, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4248, 0.7393, 0.4248, 0.4248, 0.4248, 0.4248, 0.4248, 0.4248, 0.4248,\n",
      "         0.4248, 0.4248, 0.7393]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2118, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4248, 0.7400, 0.4248, 0.4248, 0.4248, 0.4248, 0.4248, 0.4248, 0.4248,\n",
      "         0.4248, 0.4248, 0.7400]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2118, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4247, 0.7406, 0.4247, 0.4247, 0.4247, 0.4247, 0.4247, 0.4247, 0.4247,\n",
      "         0.4247, 0.4247, 0.7406]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2117, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4246, 0.7412, 0.4246, 0.4246, 0.4246, 0.4246, 0.4246, 0.4246, 0.4246,\n",
      "         0.4246, 0.4246, 0.7412]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2117, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4246, 0.7419, 0.4246, 0.4246, 0.4246, 0.4246, 0.4246, 0.4246, 0.4246,\n",
      "         0.4246, 0.4246, 0.7419]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2116, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4245, 0.7425, 0.4245, 0.4245, 0.4245, 0.4245, 0.4245, 0.4245, 0.4245,\n",
      "         0.4245, 0.4245, 0.7425]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2116, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4245, 0.7431, 0.4245, 0.4245, 0.4245, 0.4245, 0.4245, 0.4245, 0.4245,\n",
      "         0.4245, 0.4245, 0.7431]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2115, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4244, 0.7438, 0.4244, 0.4244, 0.4244, 0.4244, 0.4244, 0.4244, 0.4244,\n",
      "         0.4244, 0.4244, 0.7438]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2114, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4244, 0.7444, 0.4244, 0.4244, 0.4244, 0.4244, 0.4244, 0.4244, 0.4244,\n",
      "         0.4244, 0.4244, 0.7444]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2114, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4243, 0.7450, 0.4243, 0.4243, 0.4243, 0.4243, 0.4243, 0.4243, 0.4243,\n",
      "         0.4243, 0.4243, 0.7450]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2113, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4242, 0.7457, 0.4242, 0.4242, 0.4242, 0.4242, 0.4242, 0.4242, 0.4242,\n",
      "         0.4242, 0.4242, 0.7457]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2113, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4242, 0.7463, 0.4242, 0.4242, 0.4242, 0.4242, 0.4242, 0.4242, 0.4242,\n",
      "         0.4242, 0.4242, 0.7463]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2112, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4241, 0.7469, 0.4241, 0.4241, 0.4241, 0.4241, 0.4241, 0.4241, 0.4241,\n",
      "         0.4241, 0.4241, 0.7469]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2112, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4241, 0.7476, 0.4241, 0.4241, 0.4241, 0.4241, 0.4241, 0.4241, 0.4241,\n",
      "         0.4241, 0.4241, 0.7476]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2111, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4240, 0.7482, 0.4240, 0.4240, 0.4240, 0.4240, 0.4240, 0.4240, 0.4240,\n",
      "         0.4240, 0.4240, 0.7482]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2110, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4239, 0.7488, 0.4239, 0.4239, 0.4239, 0.4239, 0.4239, 0.4239, 0.4239,\n",
      "         0.4239, 0.4239, 0.7488]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2110, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4239, 0.7494, 0.4239, 0.4239, 0.4239, 0.4239, 0.4239, 0.4239, 0.4239,\n",
      "         0.4239, 0.4239, 0.7494]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2109, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4238, 0.7501, 0.4238, 0.4238, 0.4238, 0.4238, 0.4238, 0.4238, 0.4238,\n",
      "         0.4238, 0.4238, 0.7501]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2109, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4238, 0.7507, 0.4238, 0.4238, 0.4238, 0.4238, 0.4238, 0.4238, 0.4238,\n",
      "         0.4238, 0.4238, 0.7507]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2108, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4237, 0.7513, 0.4237, 0.4237, 0.4237, 0.4237, 0.4237, 0.4237, 0.4237,\n",
      "         0.4237, 0.4237, 0.7513]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2108, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4236, 0.7520, 0.4236, 0.4236, 0.4236, 0.4236, 0.4236, 0.4236, 0.4236,\n",
      "         0.4236, 0.4236, 0.7520]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2107, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4236, 0.7526, 0.4236, 0.4236, 0.4236, 0.4236, 0.4236, 0.4236, 0.4236,\n",
      "         0.4236, 0.4236, 0.7526]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2107, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4235, 0.7532, 0.4235, 0.4235, 0.4235, 0.4235, 0.4235, 0.4235, 0.4235,\n",
      "         0.4235, 0.4235, 0.7532]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2106, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4235, 0.7538, 0.4235, 0.4235, 0.4235, 0.4235, 0.4235, 0.4235, 0.4235,\n",
      "         0.4235, 0.4235, 0.7538]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2106, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4234, 0.7545, 0.4234, 0.4234, 0.4234, 0.4234, 0.4234, 0.4234, 0.4234,\n",
      "         0.4234, 0.4234, 0.7545]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2105, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4233, 0.7551, 0.4233, 0.4233, 0.4233, 0.4233, 0.4233, 0.4233, 0.4233,\n",
      "         0.4233, 0.4233, 0.7551]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2104, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4233, 0.7557, 0.4233, 0.4233, 0.4233, 0.4233, 0.4233, 0.4233, 0.4233,\n",
      "         0.4233, 0.4233, 0.7557]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2104, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4232, 0.7564, 0.4232, 0.4232, 0.4232, 0.4232, 0.4232, 0.4232, 0.4232,\n",
      "         0.4232, 0.4232, 0.7564]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2103, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4232, 0.7570, 0.4232, 0.4232, 0.4232, 0.4232, 0.4232, 0.4232, 0.4232,\n",
      "         0.4232, 0.4232, 0.7570]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2103, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4231, 0.7576, 0.4231, 0.4231, 0.4231, 0.4231, 0.4231, 0.4231, 0.4231,\n",
      "         0.4231, 0.4231, 0.7576]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2102, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4230, 0.7582, 0.4230, 0.4230, 0.4230, 0.4230, 0.4230, 0.4230, 0.4230,\n",
      "         0.4230, 0.4230, 0.7582]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2102, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4230, 0.7589, 0.4230, 0.4230, 0.4230, 0.4230, 0.4230, 0.4230, 0.4230,\n",
      "         0.4230, 0.4230, 0.7589]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2101, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4229, 0.7595, 0.4229, 0.4229, 0.4229, 0.4229, 0.4229, 0.4229, 0.4229,\n",
      "         0.4229, 0.4229, 0.7595]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2101, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4229, 0.7601, 0.4229, 0.4229, 0.4229, 0.4229, 0.4229, 0.4229, 0.4229,\n",
      "         0.4229, 0.4229, 0.7601]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2100, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4228, 0.7607, 0.4228, 0.4228, 0.4228, 0.4228, 0.4228, 0.4228, 0.4228,\n",
      "         0.4228, 0.4228, 0.7607]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2100, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4227, 0.7614, 0.4227, 0.4227, 0.4227, 0.4227, 0.4227, 0.4227, 0.4227,\n",
      "         0.4227, 0.4227, 0.7614]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2099, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4227, 0.7620, 0.4227, 0.4227, 0.4227, 0.4227, 0.4227, 0.4227, 0.4227,\n",
      "         0.4227, 0.4227, 0.7620]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2099, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4226, 0.7626, 0.4226, 0.4226, 0.4226, 0.4226, 0.4226, 0.4226, 0.4226,\n",
      "         0.4226, 0.4226, 0.7626]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2098, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4226, 0.7632, 0.4226, 0.4226, 0.4226, 0.4226, 0.4226, 0.4226, 0.4226,\n",
      "         0.4226, 0.4226, 0.7632]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2098, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4225, 0.7639, 0.4225, 0.4225, 0.4225, 0.4225, 0.4225, 0.4225, 0.4225,\n",
      "         0.4225, 0.4225, 0.7639]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2097, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4225, 0.7645, 0.4225, 0.4225, 0.4225, 0.4225, 0.4225, 0.4225, 0.4225,\n",
      "         0.4225, 0.4225, 0.7645]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2097, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4224, 0.7651, 0.4224, 0.4224, 0.4224, 0.4224, 0.4224, 0.4224, 0.4224,\n",
      "         0.4224, 0.4224, 0.7651]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2096, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4223, 0.7657, 0.4223, 0.4223, 0.4223, 0.4223, 0.4223, 0.4223, 0.4223,\n",
      "         0.4223, 0.4223, 0.7657]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2096, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4223, 0.7664, 0.4223, 0.4223, 0.4223, 0.4223, 0.4223, 0.4223, 0.4223,\n",
      "         0.4223, 0.4223, 0.7664]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2095, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4222, 0.7670, 0.4222, 0.4222, 0.4222, 0.4222, 0.4222, 0.4222, 0.4222,\n",
      "         0.4222, 0.4222, 0.7670]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2095, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4222, 0.7676, 0.4222, 0.4222, 0.4222, 0.4222, 0.4222, 0.4222, 0.4222,\n",
      "         0.4222, 0.4222, 0.7676]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2094, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4221, 0.7682, 0.4221, 0.4221, 0.4221, 0.4221, 0.4221, 0.4221, 0.4221,\n",
      "         0.4221, 0.4221, 0.7682]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2094, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4220, 0.7688, 0.4220, 0.4220, 0.4220, 0.4220, 0.4220, 0.4220, 0.4220,\n",
      "         0.4220, 0.4220, 0.7688]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2093, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4220, 0.7695, 0.4220, 0.4220, 0.4220, 0.4220, 0.4220, 0.4220, 0.4220,\n",
      "         0.4220, 0.4220, 0.7695]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2093, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4219, 0.7701, 0.4219, 0.4219, 0.4219, 0.4219, 0.4219, 0.4219, 0.4219,\n",
      "         0.4219, 0.4219, 0.7701]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2092, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4219, 0.7707, 0.4219, 0.4219, 0.4219, 0.4219, 0.4219, 0.4219, 0.4219,\n",
      "         0.4219, 0.4219, 0.7707]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2092, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4218, 0.7713, 0.4218, 0.4218, 0.4218, 0.4218, 0.4218, 0.4218, 0.4218,\n",
      "         0.4218, 0.4218, 0.7713]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2091, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4217, 0.7719, 0.4217, 0.4217, 0.4217, 0.4217, 0.4217, 0.4217, 0.4217,\n",
      "         0.4217, 0.4217, 0.7719]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2091, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4217, 0.7725, 0.4217, 0.4217, 0.4217, 0.4217, 0.4217, 0.4217, 0.4217,\n",
      "         0.4217, 0.4217, 0.7725]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2090, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4216, 0.7732, 0.4216, 0.4216, 0.4216, 0.4216, 0.4216, 0.4216, 0.4216,\n",
      "         0.4216, 0.4216, 0.7732]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2090, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4216, 0.7738, 0.4216, 0.4216, 0.4216, 0.4216, 0.4216, 0.4216, 0.4216,\n",
      "         0.4216, 0.4216, 0.7738]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2089, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4215, 0.7744, 0.4215, 0.4215, 0.4215, 0.4215, 0.4215, 0.4215, 0.4215,\n",
      "         0.4215, 0.4215, 0.7744]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2089, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4214, 0.7750, 0.4214, 0.4214, 0.4214, 0.4214, 0.4214, 0.4214, 0.4214,\n",
      "         0.4214, 0.4214, 0.7750]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2088, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4214, 0.7756, 0.4214, 0.4214, 0.4214, 0.4214, 0.4214, 0.4214, 0.4214,\n",
      "         0.4214, 0.4214, 0.7756]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2088, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4213, 0.7762, 0.4213, 0.4213, 0.4213, 0.4213, 0.4213, 0.4213, 0.4213,\n",
      "         0.4213, 0.4213, 0.7762]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2087, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4213, 0.7769, 0.4213, 0.4213, 0.4213, 0.4213, 0.4213, 0.4213, 0.4213,\n",
      "         0.4213, 0.4213, 0.7769]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2087, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4212, 0.7775, 0.4212, 0.4212, 0.4212, 0.4212, 0.4212, 0.4212, 0.4212,\n",
      "         0.4212, 0.4212, 0.7775]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2086, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4212, 0.7781, 0.4212, 0.4212, 0.4212, 0.4212, 0.4212, 0.4212, 0.4212,\n",
      "         0.4212, 0.4212, 0.7781]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2086, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4211, 0.7787, 0.4211, 0.4211, 0.4211, 0.4211, 0.4211, 0.4211, 0.4211,\n",
      "         0.4211, 0.4211, 0.7787]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2085, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4210, 0.7793, 0.4210, 0.4210, 0.4210, 0.4210, 0.4210, 0.4210, 0.4210,\n",
      "         0.4210, 0.4210, 0.7793]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2085, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4210, 0.7799, 0.4210, 0.4210, 0.4210, 0.4210, 0.4210, 0.4210, 0.4210,\n",
      "         0.4210, 0.4210, 0.7799]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2084, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4209, 0.7805, 0.4209, 0.4209, 0.4209, 0.4209, 0.4209, 0.4209, 0.4209,\n",
      "         0.4209, 0.4209, 0.7805]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2084, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4209, 0.7811, 0.4209, 0.4209, 0.4209, 0.4209, 0.4209, 0.4209, 0.4209,\n",
      "         0.4209, 0.4209, 0.7811]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2083, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4208, 0.7818, 0.4208, 0.4208, 0.4208, 0.4208, 0.4208, 0.4208, 0.4208,\n",
      "         0.4208, 0.4208, 0.7818]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2083, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4207, 0.7824, 0.4207, 0.4207, 0.4207, 0.4207, 0.4207, 0.4207, 0.4207,\n",
      "         0.4207, 0.4207, 0.7824]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2083, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4207, 0.7830, 0.4207, 0.4207, 0.4207, 0.4207, 0.4207, 0.4207, 0.4207,\n",
      "         0.4207, 0.4207, 0.7830]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2082, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4206, 0.7836, 0.4206, 0.4206, 0.4206, 0.4206, 0.4206, 0.4206, 0.4206,\n",
      "         0.4206, 0.4206, 0.7836]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2082, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4206, 0.7842, 0.4206, 0.4206, 0.4206, 0.4206, 0.4206, 0.4206, 0.4206,\n",
      "         0.4206, 0.4206, 0.7842]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2081, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4205, 0.7848, 0.4205, 0.4205, 0.4205, 0.4205, 0.4205, 0.4205, 0.4205,\n",
      "         0.4205, 0.4205, 0.7848]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2081, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4205, 0.7854, 0.4205, 0.4205, 0.4205, 0.4205, 0.4205, 0.4205, 0.4205,\n",
      "         0.4205, 0.4205, 0.7854]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2080, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4204, 0.7860, 0.4204, 0.4204, 0.4204, 0.4204, 0.4204, 0.4204, 0.4204,\n",
      "         0.4204, 0.4204, 0.7860]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2080, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4203, 0.7866, 0.4203, 0.4203, 0.4203, 0.4203, 0.4203, 0.4203, 0.4203,\n",
      "         0.4203, 0.4203, 0.7866]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2079, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4203, 0.7872, 0.4203, 0.4203, 0.4203, 0.4203, 0.4203, 0.4203, 0.4203,\n",
      "         0.4203, 0.4203, 0.7872]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2079, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4202, 0.7878, 0.4202, 0.4202, 0.4202, 0.4202, 0.4202, 0.4202, 0.4202,\n",
      "         0.4202, 0.4202, 0.7878]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2078, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4202, 0.7884, 0.4202, 0.4202, 0.4202, 0.4202, 0.4202, 0.4202, 0.4202,\n",
      "         0.4202, 0.4202, 0.7884]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2078, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4201, 0.7890, 0.4201, 0.4201, 0.4201, 0.4201, 0.4201, 0.4201, 0.4201,\n",
      "         0.4201, 0.4201, 0.7890]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2078, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4201, 0.7896, 0.4201, 0.4201, 0.4201, 0.4201, 0.4201, 0.4201, 0.4201,\n",
      "         0.4201, 0.4201, 0.7896]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2077, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4200, 0.7902, 0.4200, 0.4200, 0.4200, 0.4200, 0.4200, 0.4200, 0.4200,\n",
      "         0.4200, 0.4200, 0.7902]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2077, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4199, 0.7908, 0.4199, 0.4199, 0.4199, 0.4199, 0.4199, 0.4199, 0.4199,\n",
      "         0.4199, 0.4199, 0.7908]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2076, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4199, 0.7914, 0.4199, 0.4199, 0.4199, 0.4199, 0.4199, 0.4199, 0.4199,\n",
      "         0.4199, 0.4199, 0.7914]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2076, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4198, 0.7920, 0.4198, 0.4198, 0.4198, 0.4198, 0.4198, 0.4198, 0.4198,\n",
      "         0.4198, 0.4198, 0.7920]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2075, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4198, 0.7926, 0.4198, 0.4198, 0.4198, 0.4198, 0.4198, 0.4198, 0.4198,\n",
      "         0.4198, 0.4198, 0.7926]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2075, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4197, 0.7932, 0.4197, 0.4197, 0.4197, 0.4197, 0.4197, 0.4197, 0.4197,\n",
      "         0.4197, 0.4197, 0.7932]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2074, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4197, 0.7938, 0.4197, 0.4197, 0.4197, 0.4197, 0.4197, 0.4197, 0.4197,\n",
      "         0.4197, 0.4197, 0.7938]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2074, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4196, 0.7944, 0.4196, 0.4196, 0.4196, 0.4196, 0.4196, 0.4196, 0.4196,\n",
      "         0.4196, 0.4196, 0.7944]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2074, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4195, 0.7950, 0.4195, 0.4195, 0.4195, 0.4195, 0.4195, 0.4195, 0.4195,\n",
      "         0.4195, 0.4195, 0.7950]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2073, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4195, 0.7956, 0.4195, 0.4195, 0.4195, 0.4195, 0.4195, 0.4195, 0.4195,\n",
      "         0.4195, 0.4195, 0.7956]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2073, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4194, 0.7962, 0.4194, 0.4194, 0.4194, 0.4194, 0.4194, 0.4194, 0.4194,\n",
      "         0.4194, 0.4194, 0.7962]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2072, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4194, 0.7968, 0.4194, 0.4194, 0.4194, 0.4194, 0.4194, 0.4194, 0.4194,\n",
      "         0.4194, 0.4194, 0.7968]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2072, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4193, 0.7974, 0.4193, 0.4193, 0.4193, 0.4193, 0.4193, 0.4193, 0.4193,\n",
      "         0.4193, 0.4193, 0.7974]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2072, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4193, 0.7980, 0.4193, 0.4193, 0.4193, 0.4193, 0.4193, 0.4193, 0.4193,\n",
      "         0.4193, 0.4193, 0.7980]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2071, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4192, 0.7986, 0.4192, 0.4192, 0.4192, 0.4192, 0.4192, 0.4192, 0.4192,\n",
      "         0.4192, 0.4192, 0.7986]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2071, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4191, 0.7992, 0.4191, 0.4191, 0.4191, 0.4191, 0.4191, 0.4191, 0.4191,\n",
      "         0.4191, 0.4191, 0.7992]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2070, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4191, 0.7998, 0.4191, 0.4191, 0.4191, 0.4191, 0.4191, 0.4191, 0.4191,\n",
      "         0.4191, 0.4191, 0.7998]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2070, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4190, 0.8004, 0.4190, 0.4190, 0.4190, 0.4190, 0.4190, 0.4190, 0.4190,\n",
      "         0.4190, 0.4190, 0.8004]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2069, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4190, 0.8010, 0.4190, 0.4190, 0.4190, 0.4190, 0.4190, 0.4190, 0.4190,\n",
      "         0.4190, 0.4190, 0.8010]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2069, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4189, 0.8016, 0.4189, 0.4189, 0.4189, 0.4189, 0.4189, 0.4189, 0.4189,\n",
      "         0.4189, 0.4189, 0.8016]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2069, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4189, 0.8022, 0.4189, 0.4189, 0.4189, 0.4189, 0.4189, 0.4189, 0.4189,\n",
      "         0.4189, 0.4189, 0.8022]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2068, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4188, 0.8027, 0.4188, 0.4188, 0.4188, 0.4188, 0.4188, 0.4188, 0.4188,\n",
      "         0.4188, 0.4188, 0.8027]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2068, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4187, 0.8033, 0.4187, 0.4187, 0.4187, 0.4187, 0.4187, 0.4187, 0.4187,\n",
      "         0.4187, 0.4187, 0.8033]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2067, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4187, 0.8039, 0.4187, 0.4187, 0.4187, 0.4187, 0.4187, 0.4187, 0.4187,\n",
      "         0.4187, 0.4187, 0.8039]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2067, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4186, 0.8045, 0.4186, 0.4186, 0.4186, 0.4186, 0.4186, 0.4186, 0.4186,\n",
      "         0.4186, 0.4186, 0.8045]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2067, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4186, 0.8051, 0.4186, 0.4186, 0.4186, 0.4186, 0.4186, 0.4186, 0.4186,\n",
      "         0.4186, 0.4186, 0.8051]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2066, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4185, 0.8057, 0.4185, 0.4185, 0.4185, 0.4185, 0.4185, 0.4185, 0.4185,\n",
      "         0.4185, 0.4185, 0.8057]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2066, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4185, 0.8063, 0.4185, 0.4185, 0.4185, 0.4185, 0.4185, 0.4185, 0.4185,\n",
      "         0.4185, 0.4185, 0.8063]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2065, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4184, 0.8068, 0.4184, 0.4184, 0.4184, 0.4184, 0.4184, 0.4184, 0.4184,\n",
      "         0.4184, 0.4184, 0.8068]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2065, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4184, 0.8074, 0.4184, 0.4184, 0.4184, 0.4184, 0.4184, 0.4184, 0.4184,\n",
      "         0.4184, 0.4184, 0.8074]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2065, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4183, 0.8080, 0.4183, 0.4183, 0.4183, 0.4183, 0.4183, 0.4183, 0.4183,\n",
      "         0.4183, 0.4183, 0.8080]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2064, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4182, 0.8086, 0.4182, 0.4182, 0.4182, 0.4182, 0.4182, 0.4182, 0.4182,\n",
      "         0.4182, 0.4182, 0.8086]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2064, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4182, 0.8092, 0.4182, 0.4182, 0.4182, 0.4182, 0.4182, 0.4182, 0.4182,\n",
      "         0.4182, 0.4182, 0.8092]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2063, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4181, 0.8097, 0.4181, 0.4181, 0.4181, 0.4181, 0.4181, 0.4181, 0.4181,\n",
      "         0.4181, 0.4181, 0.8097]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2063, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4181, 0.8103, 0.4181, 0.4181, 0.4181, 0.4181, 0.4181, 0.4181, 0.4181,\n",
      "         0.4181, 0.4181, 0.8103]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2063, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4180, 0.8109, 0.4180, 0.4180, 0.4180, 0.4180, 0.4180, 0.4180, 0.4180,\n",
      "         0.4180, 0.4180, 0.8109]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2062, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4180, 0.8115, 0.4180, 0.4180, 0.4180, 0.4180, 0.4180, 0.4180, 0.4180,\n",
      "         0.4180, 0.4180, 0.8115]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2062, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4179, 0.8121, 0.4179, 0.4179, 0.4179, 0.4179, 0.4179, 0.4179, 0.4179,\n",
      "         0.4179, 0.4179, 0.8121]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2062, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4179, 0.8126, 0.4179, 0.4179, 0.4179, 0.4179, 0.4179, 0.4179, 0.4179,\n",
      "         0.4179, 0.4179, 0.8126]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2061, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4178, 0.8132, 0.4178, 0.4178, 0.4178, 0.4178, 0.4178, 0.4178, 0.4178,\n",
      "         0.4178, 0.4178, 0.8132]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2061, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4178, 0.8138, 0.4178, 0.4178, 0.4178, 0.4178, 0.4178, 0.4178, 0.4178,\n",
      "         0.4178, 0.4178, 0.8138]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2060, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4177, 0.8143, 0.4177, 0.4177, 0.4177, 0.4177, 0.4177, 0.4177, 0.4177,\n",
      "         0.4177, 0.4177, 0.8143]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2060, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4176, 0.8149, 0.4176, 0.4176, 0.4176, 0.4176, 0.4176, 0.4176, 0.4176,\n",
      "         0.4176, 0.4176, 0.8149]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2060, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4176, 0.8155, 0.4176, 0.4176, 0.4176, 0.4176, 0.4176, 0.4176, 0.4176,\n",
      "         0.4176, 0.4176, 0.8155]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2059, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4175, 0.8161, 0.4175, 0.4175, 0.4175, 0.4175, 0.4175, 0.4175, 0.4175,\n",
      "         0.4175, 0.4175, 0.8161]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2059, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4175, 0.8166, 0.4175, 0.4175, 0.4175, 0.4175, 0.4175, 0.4175, 0.4175,\n",
      "         0.4175, 0.4175, 0.8166]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2059, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4174, 0.8172, 0.4174, 0.4174, 0.4174, 0.4174, 0.4174, 0.4174, 0.4174,\n",
      "         0.4174, 0.4174, 0.8172]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2058, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4174, 0.8178, 0.4174, 0.4174, 0.4174, 0.4174, 0.4174, 0.4174, 0.4174,\n",
      "         0.4174, 0.4174, 0.8178]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2058, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4173, 0.8183, 0.4173, 0.4173, 0.4173, 0.4173, 0.4173, 0.4173, 0.4173,\n",
      "         0.4173, 0.4173, 0.8183]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2058, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4173, 0.8189, 0.4173, 0.4173, 0.4173, 0.4173, 0.4173, 0.4173, 0.4173,\n",
      "         0.4173, 0.4173, 0.8189]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2057, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4172, 0.8195, 0.4172, 0.4172, 0.4172, 0.4172, 0.4172, 0.4172, 0.4172,\n",
      "         0.4172, 0.4172, 0.8195]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2057, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4172, 0.8200, 0.4172, 0.4172, 0.4172, 0.4172, 0.4172, 0.4172, 0.4172,\n",
      "         0.4172, 0.4172, 0.8200]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2056, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4171, 0.8206, 0.4171, 0.4171, 0.4171, 0.4171, 0.4171, 0.4171, 0.4171,\n",
      "         0.4171, 0.4171, 0.8206]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2056, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4170, 0.8212, 0.4170, 0.4170, 0.4170, 0.4170, 0.4170, 0.4170, 0.4170,\n",
      "         0.4170, 0.4170, 0.8212]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2056, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4170, 0.8217, 0.4170, 0.4170, 0.4170, 0.4170, 0.4170, 0.4170, 0.4170,\n",
      "         0.4170, 0.4170, 0.8217]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2055, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4169, 0.8223, 0.4169, 0.4169, 0.4169, 0.4169, 0.4169, 0.4169, 0.4169,\n",
      "         0.4169, 0.4169, 0.8223]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2055, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4169, 0.8228, 0.4169, 0.4169, 0.4169, 0.4169, 0.4169, 0.4169, 0.4169,\n",
      "         0.4169, 0.4169, 0.8228]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2055, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4168, 0.8234, 0.4168, 0.4168, 0.4168, 0.4168, 0.4168, 0.4168, 0.4168,\n",
      "         0.4168, 0.4168, 0.8234]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2054, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4168, 0.8240, 0.4168, 0.4168, 0.4168, 0.4168, 0.4168, 0.4168, 0.4168,\n",
      "         0.4168, 0.4168, 0.8240]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2054, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4167, 0.8245, 0.4167, 0.4167, 0.4167, 0.4167, 0.4167, 0.4167, 0.4167,\n",
      "         0.4167, 0.4167, 0.8245]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2054, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4167, 0.8251, 0.4167, 0.4167, 0.4167, 0.4167, 0.4167, 0.4167, 0.4167,\n",
      "         0.4167, 0.4167, 0.8251]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2053, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4166, 0.8256, 0.4166, 0.4166, 0.4166, 0.4166, 0.4166, 0.4166, 0.4166,\n",
      "         0.4166, 0.4166, 0.8256]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2053, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4166, 0.8262, 0.4166, 0.4166, 0.4166, 0.4166, 0.4166, 0.4166, 0.4166,\n",
      "         0.4166, 0.4166, 0.8262]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2053, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4165, 0.8267, 0.4165, 0.4165, 0.4165, 0.4165, 0.4165, 0.4165, 0.4165,\n",
      "         0.4165, 0.4165, 0.8267]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2052, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4165, 0.8273, 0.4165, 0.4165, 0.4165, 0.4165, 0.4165, 0.4165, 0.4165,\n",
      "         0.4165, 0.4165, 0.8273]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2052, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4164, 0.8278, 0.4164, 0.4164, 0.4164, 0.4164, 0.4164, 0.4164, 0.4164,\n",
      "         0.4164, 0.4164, 0.8278]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2052, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4164, 0.8284, 0.4164, 0.4164, 0.4164, 0.4164, 0.4164, 0.4164, 0.4164,\n",
      "         0.4164, 0.4164, 0.8284]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2051, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4163, 0.8290, 0.4163, 0.4163, 0.4163, 0.4163, 0.4163, 0.4163, 0.4163,\n",
      "         0.4163, 0.4163, 0.8290]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2051, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4163, 0.8295, 0.4163, 0.4163, 0.4163, 0.4163, 0.4163, 0.4163, 0.4163,\n",
      "         0.4163, 0.4163, 0.8295]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2051, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4162, 0.8301, 0.4162, 0.4162, 0.4162, 0.4162, 0.4162, 0.4162, 0.4162,\n",
      "         0.4162, 0.4162, 0.8301]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2050, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4161, 0.8306, 0.4161, 0.4161, 0.4161, 0.4161, 0.4161, 0.4161, 0.4161,\n",
      "         0.4161, 0.4161, 0.8306]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2050, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4161, 0.8311, 0.4161, 0.4161, 0.4161, 0.4161, 0.4161, 0.4161, 0.4161,\n",
      "         0.4161, 0.4161, 0.8311]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2050, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4160, 0.8317, 0.4160, 0.4160, 0.4160, 0.4160, 0.4160, 0.4160, 0.4160,\n",
      "         0.4160, 0.4160, 0.8317]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2049, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4160, 0.8322, 0.4160, 0.4160, 0.4160, 0.4160, 0.4160, 0.4160, 0.4160,\n",
      "         0.4160, 0.4160, 0.8322]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2049, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4159, 0.8328, 0.4159, 0.4159, 0.4159, 0.4159, 0.4159, 0.4159, 0.4159,\n",
      "         0.4159, 0.4159, 0.8328]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2049, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4159, 0.8333, 0.4159, 0.4159, 0.4159, 0.4159, 0.4159, 0.4159, 0.4159,\n",
      "         0.4159, 0.4159, 0.8333]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2048, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4158, 0.8339, 0.4158, 0.4158, 0.4158, 0.4158, 0.4158, 0.4158, 0.4158,\n",
      "         0.4158, 0.4158, 0.8339]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2048, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4158, 0.8344, 0.4158, 0.4158, 0.4158, 0.4158, 0.4158, 0.4158, 0.4158,\n",
      "         0.4158, 0.4158, 0.8344]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2048, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4157, 0.8349, 0.4157, 0.4157, 0.4157, 0.4157, 0.4157, 0.4157, 0.4157,\n",
      "         0.4157, 0.4157, 0.8349]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2047, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4157, 0.8355, 0.4157, 0.4157, 0.4157, 0.4157, 0.4157, 0.4157, 0.4157,\n",
      "         0.4157, 0.4157, 0.8355]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2047, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4156, 0.8360, 0.4156, 0.4156, 0.4156, 0.4156, 0.4156, 0.4156, 0.4156,\n",
      "         0.4156, 0.4156, 0.8360]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2047, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4156, 0.8366, 0.4156, 0.4156, 0.4156, 0.4156, 0.4156, 0.4156, 0.4156,\n",
      "         0.4156, 0.4156, 0.8366]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2047, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4155, 0.8371, 0.4155, 0.4155, 0.4155, 0.4155, 0.4155, 0.4155, 0.4155,\n",
      "         0.4155, 0.4155, 0.8371]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2046, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4155, 0.8376, 0.4155, 0.4155, 0.4155, 0.4155, 0.4155, 0.4155, 0.4155,\n",
      "         0.4155, 0.4155, 0.8376]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2046, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4154, 0.8382, 0.4154, 0.4154, 0.4154, 0.4154, 0.4154, 0.4154, 0.4154,\n",
      "         0.4154, 0.4154, 0.8382]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2046, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4154, 0.8387, 0.4154, 0.4154, 0.4154, 0.4154, 0.4154, 0.4154, 0.4154,\n",
      "         0.4154, 0.4154, 0.8387]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2045, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4153, 0.8392, 0.4153, 0.4153, 0.4153, 0.4153, 0.4153, 0.4153, 0.4153,\n",
      "         0.4153, 0.4153, 0.8392]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2045, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4153, 0.8398, 0.4153, 0.4153, 0.4153, 0.4153, 0.4153, 0.4153, 0.4153,\n",
      "         0.4153, 0.4153, 0.8398]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2045, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4152, 0.8403, 0.4152, 0.4152, 0.4152, 0.4152, 0.4152, 0.4152, 0.4152,\n",
      "         0.4152, 0.4152, 0.8403]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2044, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4152, 0.8408, 0.4152, 0.4152, 0.4152, 0.4152, 0.4152, 0.4152, 0.4152,\n",
      "         0.4152, 0.4152, 0.8408]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2044, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4151, 0.8414, 0.4151, 0.4151, 0.4151, 0.4151, 0.4151, 0.4151, 0.4151,\n",
      "         0.4151, 0.4151, 0.8414]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2044, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4151, 0.8419, 0.4151, 0.4151, 0.4151, 0.4151, 0.4151, 0.4151, 0.4151,\n",
      "         0.4151, 0.4151, 0.8419]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2044, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4150, 0.8424, 0.4150, 0.4150, 0.4150, 0.4150, 0.4150, 0.4150, 0.4150,\n",
      "         0.4150, 0.4150, 0.8424]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2043, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4150, 0.8429, 0.4150, 0.4150, 0.4150, 0.4150, 0.4150, 0.4150, 0.4150,\n",
      "         0.4150, 0.4150, 0.8429]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2043, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4149, 0.8435, 0.4149, 0.4149, 0.4149, 0.4149, 0.4149, 0.4149, 0.4149,\n",
      "         0.4149, 0.4149, 0.8435]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2043, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4149, 0.8440, 0.4149, 0.4149, 0.4149, 0.4149, 0.4149, 0.4149, 0.4149,\n",
      "         0.4149, 0.4149, 0.8440]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2042, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4148, 0.8445, 0.4148, 0.4148, 0.4148, 0.4148, 0.4148, 0.4148, 0.4148,\n",
      "         0.4148, 0.4148, 0.8445]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2042, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4148, 0.8450, 0.4148, 0.4148, 0.4148, 0.4148, 0.4148, 0.4148, 0.4148,\n",
      "         0.4148, 0.4148, 0.8450]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2042, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4147, 0.8456, 0.4147, 0.4147, 0.4147, 0.4147, 0.4147, 0.4147, 0.4147,\n",
      "         0.4147, 0.4147, 0.8456]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2042, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4147, 0.8461, 0.4147, 0.4147, 0.4147, 0.4147, 0.4147, 0.4147, 0.4147,\n",
      "         0.4147, 0.4147, 0.8461]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2041, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4146, 0.8466, 0.4146, 0.4146, 0.4146, 0.4146, 0.4146, 0.4146, 0.4146,\n",
      "         0.4146, 0.4146, 0.8466]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2041, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4146, 0.8471, 0.4146, 0.4146, 0.4146, 0.4146, 0.4146, 0.4146, 0.4146,\n",
      "         0.4146, 0.4146, 0.8471]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2041, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4145, 0.8476, 0.4145, 0.4145, 0.4145, 0.4145, 0.4145, 0.4145, 0.4145,\n",
      "         0.4145, 0.4145, 0.8476]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2040, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4145, 0.8482, 0.4145, 0.4145, 0.4145, 0.4145, 0.4145, 0.4145, 0.4145,\n",
      "         0.4145, 0.4145, 0.8482]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2040, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4144, 0.8487, 0.4144, 0.4144, 0.4144, 0.4144, 0.4144, 0.4144, 0.4144,\n",
      "         0.4144, 0.4144, 0.8487]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2040, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4144, 0.8492, 0.4144, 0.4144, 0.4144, 0.4144, 0.4144, 0.4144, 0.4144,\n",
      "         0.4144, 0.4144, 0.8492]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2040, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4143, 0.8497, 0.4143, 0.4143, 0.4143, 0.4143, 0.4143, 0.4143, 0.4143,\n",
      "         0.4143, 0.4143, 0.8497]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2039, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4143, 0.8502, 0.4143, 0.4143, 0.4143, 0.4143, 0.4143, 0.4143, 0.4143,\n",
      "         0.4143, 0.4143, 0.8502]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2039, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4142, 0.8507, 0.4142, 0.4142, 0.4142, 0.4142, 0.4142, 0.4142, 0.4142,\n",
      "         0.4142, 0.4142, 0.8507]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2039, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4142, 0.8512, 0.4142, 0.4142, 0.4142, 0.4142, 0.4142, 0.4142, 0.4142,\n",
      "         0.4142, 0.4142, 0.8512]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2039, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4141, 0.8517, 0.4141, 0.4141, 0.4141, 0.4141, 0.4141, 0.4141, 0.4141,\n",
      "         0.4141, 0.4141, 0.8517]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2038, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4141, 0.8523, 0.4141, 0.4141, 0.4141, 0.4141, 0.4141, 0.4141, 0.4141,\n",
      "         0.4141, 0.4141, 0.8523]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2038, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4140, 0.8528, 0.4140, 0.4140, 0.4140, 0.4140, 0.4140, 0.4140, 0.4140,\n",
      "         0.4140, 0.4140, 0.8528]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2038, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4140, 0.8533, 0.4140, 0.4140, 0.4140, 0.4140, 0.4140, 0.4140, 0.4140,\n",
      "         0.4140, 0.4140, 0.8533]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2038, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4139, 0.8538, 0.4139, 0.4139, 0.4139, 0.4139, 0.4139, 0.4139, 0.4139,\n",
      "         0.4139, 0.4139, 0.8538]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2037, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4139, 0.8543, 0.4139, 0.4139, 0.4139, 0.4139, 0.4139, 0.4139, 0.4139,\n",
      "         0.4139, 0.4139, 0.8543]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2037, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4138, 0.8548, 0.4138, 0.4138, 0.4138, 0.4138, 0.4138, 0.4138, 0.4138,\n",
      "         0.4138, 0.4138, 0.8548]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2037, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4138, 0.8553, 0.4138, 0.4138, 0.4138, 0.4138, 0.4138, 0.4138, 0.4138,\n",
      "         0.4138, 0.4138, 0.8553]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2036, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4137, 0.8558, 0.4137, 0.4137, 0.4137, 0.4137, 0.4137, 0.4137, 0.4137,\n",
      "         0.4137, 0.4137, 0.8558]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2036, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4137, 0.8563, 0.4137, 0.4137, 0.4137, 0.4137, 0.4137, 0.4137, 0.4137,\n",
      "         0.4137, 0.4137, 0.8563]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2036, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4137, 0.8568, 0.4137, 0.4137, 0.4137, 0.4137, 0.4137, 0.4137, 0.4137,\n",
      "         0.4137, 0.4137, 0.8568]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2036, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4136, 0.8573, 0.4136, 0.4136, 0.4136, 0.4136, 0.4136, 0.4136, 0.4136,\n",
      "         0.4136, 0.4136, 0.8573]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2035, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4136, 0.8578, 0.4136, 0.4136, 0.4136, 0.4136, 0.4136, 0.4136, 0.4136,\n",
      "         0.4136, 0.4136, 0.8578]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2035, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4135, 0.8583, 0.4135, 0.4135, 0.4135, 0.4135, 0.4135, 0.4135, 0.4135,\n",
      "         0.4135, 0.4135, 0.8583]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2035, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4135, 0.8588, 0.4135, 0.4135, 0.4135, 0.4135, 0.4135, 0.4135, 0.4135,\n",
      "         0.4135, 0.4135, 0.8588]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2035, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4134, 0.8593, 0.4134, 0.4134, 0.4134, 0.4134, 0.4134, 0.4134, 0.4134,\n",
      "         0.4134, 0.4134, 0.8593]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2035, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4134, 0.8598, 0.4134, 0.4134, 0.4134, 0.4134, 0.4134, 0.4134, 0.4134,\n",
      "         0.4134, 0.4134, 0.8598]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2034, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4133, 0.8603, 0.4133, 0.4133, 0.4133, 0.4133, 0.4133, 0.4133, 0.4133,\n",
      "         0.4133, 0.4133, 0.8603]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2034, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4133, 0.8607, 0.4133, 0.4133, 0.4133, 0.4133, 0.4133, 0.4133, 0.4133,\n",
      "         0.4133, 0.4133, 0.8607]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2034, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4132, 0.8612, 0.4132, 0.4132, 0.4132, 0.4132, 0.4132, 0.4132, 0.4132,\n",
      "         0.4132, 0.4132, 0.8612]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2034, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4132, 0.8617, 0.4132, 0.4132, 0.4132, 0.4132, 0.4132, 0.4132, 0.4132,\n",
      "         0.4132, 0.4132, 0.8617]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2033, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4131, 0.8622, 0.4131, 0.4131, 0.4131, 0.4131, 0.4131, 0.4131, 0.4131,\n",
      "         0.4131, 0.4131, 0.8622]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2033, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4131, 0.8627, 0.4131, 0.4131, 0.4131, 0.4131, 0.4131, 0.4131, 0.4131,\n",
      "         0.4131, 0.4131, 0.8627]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2033, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4130, 0.8632, 0.4130, 0.4130, 0.4130, 0.4130, 0.4130, 0.4130, 0.4130,\n",
      "         0.4130, 0.4130, 0.8632]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2033, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4130, 0.8637, 0.4130, 0.4130, 0.4130, 0.4130, 0.4130, 0.4130, 0.4130,\n",
      "         0.4130, 0.4130, 0.8637]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2032, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4130, 0.8642, 0.4130, 0.4130, 0.4130, 0.4130, 0.4130, 0.4130, 0.4130,\n",
      "         0.4130, 0.4130, 0.8642]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2032, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4129, 0.8646, 0.4129, 0.4129, 0.4129, 0.4129, 0.4129, 0.4129, 0.4129,\n",
      "         0.4129, 0.4129, 0.8646]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2032, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4129, 0.8651, 0.4129, 0.4129, 0.4129, 0.4129, 0.4129, 0.4129, 0.4129,\n",
      "         0.4129, 0.4129, 0.8651]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2032, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4128, 0.8656, 0.4128, 0.4128, 0.4128, 0.4128, 0.4128, 0.4128, 0.4128,\n",
      "         0.4128, 0.4128, 0.8656]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2031, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4128, 0.8661, 0.4128, 0.4128, 0.4128, 0.4128, 0.4128, 0.4128, 0.4128,\n",
      "         0.4128, 0.4128, 0.8661]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2031, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4127, 0.8666, 0.4127, 0.4127, 0.4127, 0.4127, 0.4127, 0.4127, 0.4127,\n",
      "         0.4127, 0.4127, 0.8666]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2031, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4127, 0.8670, 0.4127, 0.4127, 0.4127, 0.4127, 0.4127, 0.4127, 0.4127,\n",
      "         0.4127, 0.4127, 0.8670]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2031, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4126, 0.8675, 0.4126, 0.4126, 0.4126, 0.4126, 0.4126, 0.4126, 0.4126,\n",
      "         0.4126, 0.4126, 0.8675]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2031, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4126, 0.8680, 0.4126, 0.4126, 0.4126, 0.4126, 0.4126, 0.4126, 0.4126,\n",
      "         0.4126, 0.4126, 0.8680]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2030, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4125, 0.8685, 0.4125, 0.4125, 0.4125, 0.4125, 0.4125, 0.4125, 0.4125,\n",
      "         0.4125, 0.4125, 0.8685]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2030, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4125, 0.8689, 0.4125, 0.4125, 0.4125, 0.4125, 0.4125, 0.4125, 0.4125,\n",
      "         0.4125, 0.4125, 0.8689]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2030, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4124, 0.8694, 0.4124, 0.4124, 0.4124, 0.4124, 0.4124, 0.4124, 0.4124,\n",
      "         0.4124, 0.4124, 0.8694]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2030, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4124, 0.8699, 0.4124, 0.4124, 0.4124, 0.4124, 0.4124, 0.4124, 0.4124,\n",
      "         0.4124, 0.4124, 0.8699]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2030, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4124, 0.8704, 0.4124, 0.4124, 0.4124, 0.4124, 0.4124, 0.4124, 0.4124,\n",
      "         0.4124, 0.4124, 0.8704]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2029, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4123, 0.8708, 0.4123, 0.4123, 0.4123, 0.4123, 0.4123, 0.4123, 0.4123,\n",
      "         0.4123, 0.4123, 0.8708]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2029, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4123, 0.8713, 0.4123, 0.4123, 0.4123, 0.4123, 0.4123, 0.4123, 0.4123,\n",
      "         0.4123, 0.4123, 0.8713]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2029, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4122, 0.8718, 0.4122, 0.4122, 0.4122, 0.4122, 0.4122, 0.4122, 0.4122,\n",
      "         0.4122, 0.4122, 0.8718]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2029, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4122, 0.8722, 0.4122, 0.4122, 0.4122, 0.4122, 0.4122, 0.4122, 0.4122,\n",
      "         0.4122, 0.4122, 0.8722]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2028, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4121, 0.8727, 0.4121, 0.4121, 0.4121, 0.4121, 0.4121, 0.4121, 0.4121,\n",
      "         0.4121, 0.4121, 0.8727]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2028, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4121, 0.8732, 0.4121, 0.4121, 0.4121, 0.4121, 0.4121, 0.4121, 0.4121,\n",
      "         0.4121, 0.4121, 0.8732]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2028, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4120, 0.8736, 0.4120, 0.4120, 0.4120, 0.4120, 0.4120, 0.4120, 0.4120,\n",
      "         0.4120, 0.4120, 0.8736]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2028, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4120, 0.8741, 0.4120, 0.4120, 0.4120, 0.4120, 0.4120, 0.4120, 0.4120,\n",
      "         0.4120, 0.4120, 0.8741]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2028, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4120, 0.8745, 0.4120, 0.4120, 0.4120, 0.4120, 0.4120, 0.4120, 0.4120,\n",
      "         0.4120, 0.4120, 0.8745]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2027, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4119, 0.8750, 0.4119, 0.4119, 0.4119, 0.4119, 0.4119, 0.4119, 0.4119,\n",
      "         0.4119, 0.4119, 0.8750]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2027, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4119, 0.8755, 0.4119, 0.4119, 0.4119, 0.4119, 0.4119, 0.4119, 0.4119,\n",
      "         0.4119, 0.4119, 0.8755]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2027, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4118, 0.8759, 0.4118, 0.4118, 0.4118, 0.4118, 0.4118, 0.4118, 0.4118,\n",
      "         0.4118, 0.4118, 0.8759]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2027, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4118, 0.8764, 0.4118, 0.4118, 0.4118, 0.4118, 0.4118, 0.4118, 0.4118,\n",
      "         0.4118, 0.4118, 0.8764]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2027, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4117, 0.8768, 0.4117, 0.4117, 0.4117, 0.4117, 0.4117, 0.4117, 0.4117,\n",
      "         0.4117, 0.4117, 0.8768]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2026, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4117, 0.8773, 0.4117, 0.4117, 0.4117, 0.4117, 0.4117, 0.4117, 0.4117,\n",
      "         0.4117, 0.4117, 0.8773]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2026, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4117, 0.8777, 0.4117, 0.4117, 0.4117, 0.4117, 0.4117, 0.4117, 0.4117,\n",
      "         0.4117, 0.4117, 0.8777]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2026, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4116, 0.8782, 0.4116, 0.4116, 0.4116, 0.4116, 0.4116, 0.4116, 0.4116,\n",
      "         0.4116, 0.4116, 0.8782]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2026, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4116, 0.8786, 0.4116, 0.4116, 0.4116, 0.4116, 0.4116, 0.4116, 0.4116,\n",
      "         0.4116, 0.4116, 0.8786]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2026, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4115, 0.8791, 0.4115, 0.4115, 0.4115, 0.4115, 0.4115, 0.4115, 0.4115,\n",
      "         0.4115, 0.4115, 0.8791]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2025, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4115, 0.8795, 0.4115, 0.4115, 0.4115, 0.4115, 0.4115, 0.4115, 0.4115,\n",
      "         0.4115, 0.4115, 0.8795]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2025, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4114, 0.8800, 0.4114, 0.4114, 0.4114, 0.4114, 0.4114, 0.4114, 0.4114,\n",
      "         0.4114, 0.4114, 0.8800]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2025, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4114, 0.8804, 0.4114, 0.4114, 0.4114, 0.4114, 0.4114, 0.4114, 0.4114,\n",
      "         0.4114, 0.4114, 0.8804]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2025, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4114, 0.8809, 0.4114, 0.4114, 0.4114, 0.4114, 0.4114, 0.4114, 0.4114,\n",
      "         0.4114, 0.4114, 0.8809]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2025, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4113, 0.8813, 0.4113, 0.4113, 0.4113, 0.4113, 0.4113, 0.4113, 0.4113,\n",
      "         0.4113, 0.4113, 0.8813]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2025, grad_fn=<MseLossBackward0>)\n",
      "\n",
      "tensor([[0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.]])\n",
      "tensor([[0.4113, 0.8818, 0.4113, 0.4113, 0.4113, 0.4113, 0.4113, 0.4113, 0.4113,\n",
      "         0.4113, 0.4113, 0.8818]], grad_fn=<AddBackward0>)\n",
      "\n",
      "los is  tensor(0.2024, grad_fn=<MseLossBackward0>)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn import MSELoss, Parameter\n",
    "\n",
    "# The data function is: y = x + 10\n",
    "x_train = torch.tensor(t1)\n",
    "y_train = torch.tensor(t2, dtype=torch.float)\n",
    "\n",
    "# Simple Linear Regression: a + bx\n",
    "a = torch.randn(1, requires_grad=True, dtype=torch.float)\n",
    "b = torch.randn(1, requires_grad=True, dtype=torch.float)\n",
    "#print(\"h\",a)\n",
    "#print(\"h\",b)\n",
    "# If we use nn.Module to create a model, it will model.parameters()\n",
    "model = [Parameter(a), Parameter(b)]\n",
    "print(model)\n",
    "criterion = MSELoss()\n",
    "# optimizer = torch.optim.SGD(model, lr=0.1)\n",
    "optimizer = torch.optim.Adam(model, lr=0.01)\n",
    "\n",
    "for epoch in range(500):#500\n",
    "    # Remove the grad computed in the last step\n",
    "    optimizer.zero_grad()\n",
    "    # Run a + bx\n",
    "    y_predicted = model[0] + model[1] * x_train\n",
    "     #print(x_train, y_train)\n",
    "    print( y_train)\n",
    "    print(y_predicted)\n",
    "    loss = criterion(y_predicted, y_train)\n",
    "    loss.backward()\n",
    "    print()\n",
    "    print(\"los is \",loss)\n",
    "    print()\n",
    "    optimizer.step()\n",
    "   \n",
    "\n",
    "#print(model[0].grad)\n",
    "       # print(model[1].grad)\n",
    " \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3aff186",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'list' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 36\u001b[0m\n\u001b[1;32m     33\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Run a + bx\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m#y_predicted = model[0] + model[1] * x_train\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m y_predicted \u001b[38;5;241m=\u001b[39m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28mprint\u001b[39m(x_train, y_train, y_predicted)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'list' object is not callable"
     ]
    }
   ],
   "source": [
    "# SGD: Stochastic Gradient Descent\n",
    "# Useful links\n",
    "# https://ruder.io/optimizing-gradient-descent/\n",
    "# https://towardsdatascience.com/understanding-pytorch-with-an-example-a-step-by-step-tutorial-81fc5f8c4e8e\n",
    "\n",
    "# STEPS\n",
    "# 1. Compute Loss\n",
    "# 2. Compute Partial Derivatives\n",
    "# 3. Update the Parameters\n",
    "# 4. Repeat 1-3 until convergence\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.nn import MSELoss, Parameter\n",
    "\n",
    "# The data function is: y = x + 10\n",
    "x_train = torch.tensor([1, 2, 3, 4])\n",
    "y_train = torch.tensor([11, 12, 13, 14], dtype=torch.float)\n",
    "\n",
    "# Simple Linear Regression: a + bx\n",
    "a = torch.randn(1, requires_grad=True, dtype=torch.float)\n",
    "b = torch.randn(1, requires_grad=True, dtype=torch.float)\n",
    "\n",
    "# If we use nn.Module to create a model, it will model.parameters()\n",
    "model = [Parameter(a), Parameter(b)]\n",
    "\n",
    "criterion = MSELoss()\n",
    "# optimizer = torch.optim.SGD(model, lr=0.1)\n",
    "optimizer = torch.optim.Adam(model, lr=0.1)\n",
    "\n",
    "for epoch in range(500):\n",
    "    # Remove the grad computed in the last step\n",
    "    optimizer.zero_grad()\n",
    "    # Run a + bx\n",
    "    #y_predicted = model[0] + model[1] * x_train\n",
    "    y_predicted =model(x_train)\n",
    "    if epoch % 10 == 0:\n",
    "        print(x_train, y_train, y_predicted)\n",
    "        loss = criterion(y_predicted, y_train)\n",
    "        loss.backward()\n",
    "        print(loss)\n",
    "    optimizer.step()\n",
    "#     print(model[0].grad)\n",
    "#     print(model[1].grad)\n",
    "  \n",
    "   \n",
    "    # To get the model hyperparameters before you instantiate the class.\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492d3c8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import inspect\n",
    "import sklearn\n",
    "a = sklearn.ensemble.RandomForestRegressor\n",
    "models = [sklearn.ensemble.RandomForestRegressor, sklearn.linear_model.LinearRegression]\n",
    "\n",
    "for m in models:\n",
    "    hyperparams = \n",
    "    #inspect.getargspec(m.__init__).args\n",
    "    print(hyperparams) # Do something with them here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9680aca5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import inspect\n",
    "import sklearn\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "reg = RandomForestClassifier()\n",
    "params = reg.get_params()\n",
    "# do something...\n",
    "reg.set_params(params)\n",
    "reg.fit(X,  y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22580433",
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "import sklearn\n",
    "get_params(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88930623",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# To get the model hyperparameters before you instantiate the class\n",
    "import inspect\n",
    "import sklearn\n",
    "\n",
    "models = [sklearn.linear_model.LinearRegression]\n",
    "for m in models:\n",
    "    hyperparams = inspect.signature(m.__init__)\n",
    "    print(hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5915bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f771ee15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "SVR._get_param_names()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "aa3dc1ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Representation   [[1 0 1 1 1 1 1 1 1 1 1 0]]\n",
      "Representation   [[0 1 1 0 0 0 0 1 0 1 1 1]]\n",
      "torch.Size([1, 12])\n",
      "#samples: 1, #features: 12\n",
      "hi\n",
      "epoch  1  loss =  tensor(8.6063, grad_fn=<MseLossBackward0>)\n",
      "hi\n",
      "epoch  11  loss =  tensor(4.8435, grad_fn=<MseLossBackward0>)\n",
      "hi\n",
      "epoch  21  loss =  tensor(2.7259, grad_fn=<MseLossBackward0>)\n",
      "hi\n",
      "epoch  31  loss =  tensor(1.5341, grad_fn=<MseLossBackward0>)\n",
      "hi\n",
      "epoch  41  loss =  tensor(0.8634, grad_fn=<MseLossBackward0>)\n",
      "hi\n",
      "epoch  51  loss =  tensor(0.4859, grad_fn=<MseLossBackward0>)\n",
      "hi\n",
      "epoch  61  loss =  tensor(0.2735, grad_fn=<MseLossBackward0>)\n",
      "hi\n",
      "epoch  71  loss =  tensor(0.1539, grad_fn=<MseLossBackward0>)\n",
      "hi\n",
      "epoch  81  loss =  tensor(0.0866, grad_fn=<MseLossBackward0>)\n",
      "hi\n",
      "epoch  91  loss =  tensor(0.0487, grad_fn=<MseLossBackward0>)\n",
      "Parameter containing:\n",
      "tensor([[-0.0041],\n",
      "        [ 0.1021],\n",
      "        [ 0.3643],\n",
      "        [-0.2482],\n",
      "        [ 0.1678],\n",
      "        [-0.0734],\n",
      "        [ 0.0953],\n",
      "        [ 0.0007],\n",
      "        [ 0.0886],\n",
      "        [ 0.0906],\n",
      "        [ 0.2304],\n",
      "        [ 0.1115]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.1271,  0.4824, -0.3373,  0.9417, -0.4652,  0.0908, -0.5394,  0.8985,\n",
      "        -0.5891,  0.4610, -0.0807,  0.3126], requires_grad=True)\n",
      "\n",
      "Prediction after training: tensor([ 0.1105,  0.8909,  1.1197, -0.0510,  0.2062, -0.2027, -0.1581,  0.9013,\n",
      "        -0.2347,  0.8234,  0.8408,  0.7587], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 12*1  1*12 =1*1 ///////////////////////////////////////////////\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "document1 = 'Dog hates a cat It loves to go out and play'\n",
    "document2 = 'Cat loves to play with a ball'\n",
    "\n",
    "# converting sentences to lower case\n",
    "document1 = document1.lower()\n",
    "document2 = document2.lower()\n",
    "\n",
    "# Intialize BoWs\n",
    "count_vect = CountVectorizer()\n",
    "# fit the corpus to CountVectorizer\n",
    "count_vect.fit([document1, document2])\n",
    "\n",
    "#--------print(\"feature names \", count_vect.get_feature_names())\n",
    "\n",
    "# bag of word representation of document1\n",
    "bow1 = count_vect.transform([document1])\n",
    "t1=bow1.toarray()\n",
    "print(\"Representation  \", t1)\n",
    "\n",
    "# bag of word representation of document2\n",
    "bow2 = count_vect.transform([document2])\n",
    "t2=bow2.toarray()\n",
    "print(\"Representation  \", t2)\n",
    "\n",
    "# Output:\n",
    "# feature names  ['and', 'ball', 'cat', 'dog', 'go', 'hates', 'it', 'loves', 'out', 'play', 'to', 'with']\n",
    "\n",
    "# Representation of document1:  [[1 0 1 1 1 1 1 1 1 1 1 0]]\n",
    "# Representation of document2:  [[0 1 1 0 0 0 0 1 0 1 1 1]]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Linear regression\n",
    "# f = w * x \n",
    "\n",
    "# here : f = 2 * x\n",
    "\n",
    "# X = torch.tensor([[1], [2], [3], [4]], dtype=torch.float32)\n",
    "# Y = torch.tensor([[2], [4], [6], [8]], dtype=torch.float32)\n",
    "X = torch.tensor(t1, dtype=torch.float32)\n",
    "Y = torch.tensor(t2, dtype=torch.float32)\n",
    "print(Y.shape)\n",
    "n_samples, n_features = X.shape\n",
    "print(f'#samples: {n_samples}, #features: {n_features}')\n",
    "# 0) create a test sample\n",
    "X_test = torch.tensor([4], dtype=torch.float32)\n",
    "\n",
    "# 1) Design Model, the model has to implement the forward pass!\n",
    "# Here we can use a built-in model from PyTorch\n",
    "\n",
    "\n",
    "# we can call this mod2el with samples X\n",
    "model = nn.Linear(1,12)\n",
    "\n",
    "\n",
    "# 2) Define loss and optimizer\n",
    "learning_rate = 0.01\n",
    "n_iters = 100\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 3) Training loop\n",
    "for epoch in range(n_iters):\n",
    "    # predict = forward pass with our model\n",
    "    y_predicted = model(X_test)\n",
    "\n",
    "    # loss\n",
    "    l = loss(Y, y_predicted)\n",
    "\n",
    "    # calculate gradients = backward pass\n",
    "    l.backward()\n",
    "\n",
    "    # update weights\n",
    "    optimizer.step()\n",
    "\n",
    "    # zero the gradients after updating\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(\"hi\")\n",
    "        print('epoch ', epoch+1,' loss = ', l)\n",
    "# for i,j in model.named_parameters():\n",
    "#     print(i,j)\n",
    "#-------------------------------------------------------important\n",
    "# print(model.weight)\n",
    "# print(model.bias)\n",
    "print()\n",
    "print(f\"Prediction after training: {model(X_test)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16bcf7a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'predicted' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [3], line 33\u001b[0m\n\u001b[1;32m     29\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(y_numpy,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mro\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     30\u001b[0m plt\u001b[38;5;241m.\u001b[39mscatter(x_numpy,y_numpy)\n\u001b[0;32m---> 33\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(x_numpy,\u001b[43mpredicted\u001b[49m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     34\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'predicted' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "x_numpy,y_numpy =datasets.make_regression(n_samples=100,n_features=1,noise=20,random_state=1)\n",
    "x=torch.from_numpy(x_numpy.astype(np.float32))\n",
    "y=torch.from_numpy(x_numpy.astype(np.float32))\n",
    "# print(x_numpy,y_numpy)\n",
    "# x=torch.tensor(x_numpy.astype(np.float32))\n",
    "# y=torch.tensor(x_numpy.astype(np.float32))\n",
    "print(y.shape)\n",
    "y=y.view(y.shape[0],1)\n",
    "n_samples,n_features=x_numpy.shape\n",
    "print(y.shape)\n",
    "model=nn.Linear(n_features,1)\n",
    "loss=nn.MSELoss()\n",
    "optimizer=torch.optim.Adam(model.parameters(),0.01)\n",
    "#loop\n",
    "for i in range(100):\n",
    "    #forword and back word and updateff\n",
    "    y_predicted=model(x)\n",
    "    l=loss(y,y_predicted)\n",
    "    l.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "#     print(f'{l:.3predicted=model(x).detach().numpy()\n",
    "plt.plot(y_numpy,'ro')\n",
    "plt.scatter(x_numpy,y_numpy)\n",
    "\n",
    "\n",
    "plt.plot(x_numpy,predicted,'b')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c69ce1",
   "metadata": {},
   "source": [
    "# logistic regression \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "679becc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "#about (-1)shape\n",
    "import numpy \n",
    "a = numpy.array([[1, 2, 3, 4], [5, 6, 7, 8]])\n",
    "print(a.shape[1])\n",
    "#print(a)\n",
    "# print(a[1, 2:4])\n",
    "# k=a.reshape(-1,-1)\n",
    "# print(k.shape)\n",
    "# print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb55f8b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3.78],\n",
       "       [2.44],\n",
       "       [2.09],\n",
       "       [0.14],\n",
       "       [1.72],\n",
       "       [1.65],\n",
       "       [4.92],\n",
       "       [4.37],\n",
       "       [4.96],\n",
       "       [4.52],\n",
       "       [3.69],\n",
       "       [5.88]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = numpy.array([3.78, 2.44, 2.09, 0.14, 1.72, 1.65, 4.92, 4.37, 4.96, 4.52, 3.69, 5.88])\n",
    "print(X.shape)\n",
    "X.reshape(12,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70abdc33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from sklearn import linear_model\n",
    "\n",
    "X = numpy.array([3.78, 2.44, 0.14, 1.72, 1.65, 4.92, 4.37, 4.96, 4.52, 3.69]).reshape(-1,1)\n",
    "y = numpy.array([0, 0, 0, 0, 0, 1, 1, 1, 1, 1])\n",
    "\n",
    "logr = linear_model.LogisticRegression()\n",
    "logr.fit(X,y)\n",
    "\n",
    "#predict if tumor is cancerous where the size is 3.46mm:\n",
    "predicted = logr.predict(numpy.array([2.09]).reshape(-1,1))\n",
    "\n",
    "print(predicted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bbd2fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03c97d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([114])\n",
      "torch.Size([114, 1])\n",
      "epoch: 10, loss = 0.4597\n",
      "epoch: 20, loss = 0.3953\n",
      "epoch: 30, loss = 0.3514\n",
      "epoch: 40, loss = 0.3195\n",
      "epoch: 50, loss = 0.2951\n",
      "epoch: 60, loss = 0.2758\n",
      "epoch: 70, loss = 0.2600\n",
      "epoch: 80, loss = 0.2468\n",
      "epoch: 90, loss = 0.2356\n",
      "epoch: 100, loss = 0.2259\n",
      "accuracy: 0.9035\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "torch.nn.Module\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# 0) Prepare data\n",
    "bc = datasets.load_breast_cancer()\n",
    "X, y = bc.data, bc.target\n",
    "\n",
    "n_samples, n_features = X.shape\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)\n",
    "\n",
    "# scale\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "X_train = torch.from_numpy(X_train.astype(np.float32))\n",
    "X_test = torch.from_numpy(X_test.astype(np.float32))\n",
    "y_train = torch.from_numpy(y_train.astype(np.float32))\n",
    "y_test = torch.from_numpy(y_test.astype(np.float32))\n",
    "print(y_test.shape)\n",
    "y_train = y_train.view(y_train.shape[0], 1)\n",
    "y_test = y_test.view(y_test.shape[0], 1)\n",
    "print(y_test.shape)\n",
    "model =LogisticRegression()\n",
    "# 1) Model\n",
    "# Linear model f = wx + b , sigmoid at the end\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, n_input_features):\n",
    "         super(Model, self).__init__()\n",
    "\n",
    "         self.linear = nn.Linear(n_input_features, 1)\n",
    "    def forward(self, x):\n",
    "        y_pred = torch.sigmoid(self.linear(x))\n",
    "        return y_pred\n",
    "\n",
    "model = Model(n_features)\n",
    "\n",
    "# 2) Loss and optimizer\n",
    "num_epochs = 100\n",
    "learning_rate = 0.01\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 3) Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass and loss\n",
    "    y_pred = model(X_train)\n",
    "    loss = criterion(y_pred, y_train)\n",
    "\n",
    "    # Backward pass and update\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # zero grad before new step\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'epoch: {epoch+1}, loss = {loss.item():.4f}')\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_predicted = model(X_test)\n",
    "    y_predicted_cls = y_predicted.round()\n",
    "    acc = y_predicted_cls.eq(y_test).sum() / float(y_test.shape[0])\n",
    "    print(f'accuracy: {acc.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffc5ac8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263a12e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
